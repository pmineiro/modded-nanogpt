import os
import sys

with open(sys.argv[0]) as f:
    code = f.read()  # read the code of this file ASAP, for logging
import copy
import glob
import math
import threading
import time
import uuid
from dataclasses import dataclass
from collections import defaultdict
from itertools import accumulate
from pathlib import Path
import gc

from malbo import compute_malbo_parameters

os.environ["PYTORCH_ALLOC_CONF"] = "expandable_segments:True"
import torch

torch.empty(
    1, device=f"cuda:{os.environ['LOCAL_RANK']}", requires_grad=True
).backward()  # prevents a bug on some systems
import torch._dynamo as dynamo
import torch.distributed as dist
import torch.nn.functional as F

# torch._inductor.config.coordinate_descent_tuning = True # we have banned this flag for new records because it causes compilation to take 30min
import triton
import triton.language as tl
from kernels import get_kernel
from torch import Tensor, nn

dynamo.config.recompile_limit = 64

# -----------------------------------------------------------------------------
# Custom operators: FP8 matmul by @YouJiacheng

@torch.library.custom_op("nanogpt::mm", mutates_args=())
def mm_op(x: Tensor, w: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor, Tensor]:
    @torch.compile
    def impl(x: Tensor, w: Tensor):
        assert x.is_contiguous() and w.is_contiguous()
        x_f8 = x.div(x_s).to(torch.float8_e4m3fn)
        w_f8 = w.div(w_s).to(torch.float8_e4m3fn)
        out = torch._scaled_mm(
            x_f8,
            w_f8.T,
            out_dtype=torch.bfloat16,
            scale_a=x.new_tensor(x_s, dtype=torch.float32),
            scale_b=x.new_tensor(w_s, dtype=torch.float32),
            use_fast_accum=True,
        )
        return out, x_f8, w_f8

    return impl(x, w)

@mm_op.register_fake
def _(x: Tensor, w: Tensor, *_):
    assert x.ndim == w.ndim == 2
    assert x.shape[1] == w.shape[1]
    assert x.device == w.device
    assert x.is_contiguous() and w.is_contiguous()
    return x @ w.T, x.to(torch.float8_e4m3fn), w.to(torch.float8_e4m3fn)

@torch.library.custom_op("nanogpt::mm_backward", mutates_args=())
def mm_backward_op(g: Tensor, x_f8: Tensor, w_f8: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor]:
    @torch.compile
    def impl(grad: Tensor, x_f8: Tensor, w_f8: Tensor):
        assert grad.is_contiguous()
        x_inv_s = grad.new_tensor(x_s, dtype=torch.float32)
        w_inv_s = grad.new_tensor(w_s, dtype=torch.float32)
        grad_inv_s = grad.new_tensor(grad_s, dtype=torch.float32)
        grad_f8 = grad.div(grad_s).to(torch.float8_e5m2)
        grad_x = torch._scaled_mm(
            grad_f8,
            w_f8.T.contiguous().T,
            out_dtype=torch.bfloat16,
            scale_a=grad_inv_s,
            scale_b=w_inv_s,
            use_fast_accum=False,
        )
        # faster than grad_f8_t @ x_f8, for (d_out, d_in) == (50304, 768)
        grad_w = torch._scaled_mm(
            x_f8.T.contiguous(),
            grad_f8.T.contiguous().T,
            out_dtype=torch.float32,
            scale_a=x_inv_s,
            scale_b=grad_inv_s,
            use_fast_accum=False,
        ).T
        return grad_x, grad_w

    return impl(g, x_f8, w_f8)

@mm_backward_op.register_fake
def _(g: Tensor, x_f8: Tensor, w_f8: Tensor, *_):
    return x_f8.to(torch.bfloat16), w_f8.T.contiguous().T.to(torch.float32)

def backward(ctx, grad_out: Tensor, *_):
    x_f8, w_f8 = ctx.saved_tensors
    x_s, w_s, grad_s = ctx.scales
    grad_x, grad_w = torch.ops.nanogpt.mm_backward(
        grad_out, x_f8, w_f8, x_s, w_s, grad_s
    )
    return grad_x, grad_w, None, None, None

def setup_context(ctx: torch.autograd.function.FunctionCtx, inputs, output):
    *_, x_s, w_s, grad_s = inputs
    _, x_f8, w_f8 = output
    ctx.save_for_backward(x_f8, w_f8)
    ctx.scales = x_s, w_s, grad_s
    ctx.set_materialize_grads(False)

mm_op.register_autograd(backward, setup_context=setup_context)

# -----------------------------------------------------------------------------
# Triton kernel for symmetric matrix multiplication by @byronxu99

def _get_autotune_configs():
    return [
        triton.Config(
            {
                "BLOCK_SIZE_M": bm,
                "BLOCK_SIZE_N": bn,
                "BLOCK_SIZE_K": bk,
                "GROUP_SIZE_M": 8,
                "LOWER_UPPER": 1,
            },
            num_stages=stages,
            num_warps=warps,
        )
        for bm in [64, 128]
        for bn in [64, 128, 256]
        for bk in [64, 128]
        for stages, warps in [(3, 4), (3, 8), (4, 4)]
        if bm // bn <= 2 and bn // bm <= 2
    ]

@triton.jit
def _pid_to_block(
    pid,
    M,
    BLOCK_SIZE_M: tl.constexpr,
    BLOCK_SIZE_N: tl.constexpr,
    GROUP_SIZE_M: tl.constexpr,
):
    # Split output matrix into blocks of size (BLOCK_SIZE_M, BLOCK_SIZE_N)
    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
    num_pid_n = tl.cdiv(M, BLOCK_SIZE_N)

    # Map PID to a single matrix in batch
    batch_idx = pid // (num_pid_m * num_pid_n)
    pid = pid % (num_pid_m * num_pid_n)

    # Map PID to 2D grid of blocks
    pid_m = pid // num_pid_n
    pid_n = pid % num_pid_n
    pid_m, pid_n = tl.swizzle2d(pid_m, pid_n, num_pid_m, num_pid_n, GROUP_SIZE_M)

    m_idx = pid_m * BLOCK_SIZE_M
    n_idx = pid_n * BLOCK_SIZE_N
    return batch_idx, m_idx, n_idx

@triton.autotune(
    configs=_get_autotune_configs(),
    key=["M", "K", "a_stride_r", "a_stride_c", "c_stride_r", "c_stride_c"],
)
@triton.jit
def XXT_kernel(
    A_ptr, C_ptr,
    M, K,
    a_stride_b, a_stride_r, a_stride_c,
    c_stride_b, c_stride_r, c_stride_c,
    BLOCK_SIZE_M: tl.constexpr,
    BLOCK_SIZE_N: tl.constexpr,
    BLOCK_SIZE_K: tl.constexpr,
    GROUP_SIZE_M: tl.constexpr,
    LOWER_UPPER: tl.constexpr,
):
    pid = tl.program_id(axis=0)
    batch_idx, m_idx, n_idx = _pid_to_block(
        pid, M, BLOCK_SIZE_M, BLOCK_SIZE_N, GROUP_SIZE_M
    )

    # Skip blocks that don't need to be computed
    skip_block_below_diag = (LOWER_UPPER == 0) and (n_idx + BLOCK_SIZE_N <= m_idx)
    skip_block_above_diag = (LOWER_UPPER != 0) and (m_idx + BLOCK_SIZE_M <= n_idx)
    if skip_block_below_diag or skip_block_above_diag:
        return

    # Index into one matrix of batch
    A_ptr += batch_idx * a_stride_b
    C_ptr += batch_idx * c_stride_b

    # Create pointer arrays for A and A.T
    offs_m = (m_idx + tl.arange(0, BLOCK_SIZE_M)) % M
    offs_n = (n_idx + tl.arange(0, BLOCK_SIZE_N)) % M
    offs_k = tl.arange(0, BLOCK_SIZE_K)
    a_ptrs = A_ptr + (offs_m[:, None] * a_stride_r + offs_k[None, :] * a_stride_c)
    at_ptrs = A_ptr + (offs_k[:, None] * a_stride_c + offs_n[None, :] * a_stride_r)

    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)

    # Accumulate over blocks of K
    for k in tl.range(0, tl.cdiv(K, BLOCK_SIZE_K)):
        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)
        at = tl.load(at_ptrs, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)
        accumulator = tl.dot(a, at, accumulator)
        a_ptrs += BLOCK_SIZE_K * a_stride_c
        at_ptrs += BLOCK_SIZE_K * a_stride_c

    out_dtype = C_ptr.dtype.element_ty
    output = accumulator.to(out_dtype)

    # Store block of C
    offs_cm = m_idx + tl.arange(0, BLOCK_SIZE_M)
    offs_cn = n_idx + tl.arange(0, BLOCK_SIZE_N)
    c_ptrs = C_ptr + (offs_cm[:, None] * c_stride_r + offs_cn[None, :] * c_stride_c)
    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < M)
    tl.store(c_ptrs, output, mask=c_mask)

    # Store block of C mirrored across the diagonal
    c_ptrs_t = C_ptr + (offs_cn[:, None] * c_stride_r + offs_cm[None, :] * c_stride_c)
    c_mask_t = (offs_cn[:, None] < M) & (offs_cm[None, :] < M)
    tl.store(c_ptrs_t, output.T, mask=c_mask_t)

def XXT(A: torch.Tensor, out: torch.Tensor):
    """
    Launch Triton kernel to compute C = A @ A.T
    """
    assert A.ndim == 2 or A.ndim == 3
    M, K = A.shape[-2:]
    assert out.size(-2) == M, "Output matrix has incorrect shape"
    assert out.size(-1) == M, "Output matrix has incorrect shape"

    batch_size = A.size(0) if A.ndim == 3 else 1
    input_batch_stride = A.stride(0) if A.ndim == 3 else 0
    output_batch_stride = out.stride(0) if out.ndim == 3 else 0

    grid = lambda meta: (
        batch_size * triton.cdiv(M, meta["BLOCK_SIZE_M"]) * triton.cdiv(M, meta["BLOCK_SIZE_N"]),
    )
    XXT_kernel[grid](
        A_ptr=A,
        C_ptr=out,
        M=M,
        K=K,
        a_stride_b=input_batch_stride,
        a_stride_r=A.stride(-2),
        a_stride_c=A.stride(-1),
        c_stride_b=output_batch_stride,
        c_stride_r=out.stride(-2),
        c_stride_c=out.stride(-1),
    )
    return out

@triton.autotune(
    configs=_get_autotune_configs(),
    key=["M", "a_stride_r", "a_stride_c", "c_stride_r", "c_stride_c"],
)
@triton.jit
def ba_plus_cAA_kernel(
    A_ptr, C_ptr,
    M,
    a_stride_b, a_stride_r, a_stride_c,
    c_stride_b, c_stride_r, c_stride_c,
    alpha, beta,
    BLOCK_SIZE_M: tl.constexpr,
    BLOCK_SIZE_N: tl.constexpr,
    BLOCK_SIZE_K: tl.constexpr,
    GROUP_SIZE_M: tl.constexpr,
    LOWER_UPPER: tl.constexpr,
):
    # This is mostly duplicated from XXT_kernel, but also loads and adds a block of A
    # Performance is slightly slower than XXT_kernel, so we use two separate kernels
    pid = tl.program_id(axis=0)
    batch_idx, m_idx, n_idx = _pid_to_block(
        pid, M, BLOCK_SIZE_M, BLOCK_SIZE_N, GROUP_SIZE_M
    )

    # Skip blocks that don't need to be computed
    skip_block_below_diag = (LOWER_UPPER == 0) and (n_idx + BLOCK_SIZE_N <= m_idx)
    skip_block_above_diag = (LOWER_UPPER != 0) and (m_idx + BLOCK_SIZE_M <= n_idx)
    if skip_block_below_diag or skip_block_above_diag:
        return

    # Index into one matrix of batch
    A_ptr += batch_idx * a_stride_b
    C_ptr += batch_idx * c_stride_b

    # Create pointer arrays for A and A.T
    offs_m = (m_idx + tl.arange(0, BLOCK_SIZE_M)) % M
    offs_n = (n_idx + tl.arange(0, BLOCK_SIZE_N)) % M
    offs_k = tl.arange(0, BLOCK_SIZE_K)
    a_ptrs = A_ptr + (offs_m[:, None] * a_stride_r + offs_k[None, :] * a_stride_c)
    at_ptrs = A_ptr + (offs_k[:, None] * a_stride_c + offs_n[None, :] * a_stride_r)

    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)

    # Accumulate over blocks of K
    for k in tl.range(0, tl.cdiv(M, BLOCK_SIZE_K)):
        a = tl.load(a_ptrs, mask=offs_k[None, :] < M - k * BLOCK_SIZE_K, other=0.0)
        at = tl.load(at_ptrs, mask=offs_k[:, None] < M - k * BLOCK_SIZE_K, other=0.0)
        accumulator = tl.dot(a, at, accumulator)
        a_ptrs += BLOCK_SIZE_K * a_stride_c
        at_ptrs += BLOCK_SIZE_K * a_stride_c

    # Load block of A to add (corresponds to the current block of C)
    offs_am = m_idx + tl.arange(0, BLOCK_SIZE_M)
    offs_an = n_idx + tl.arange(0, BLOCK_SIZE_N)
    a_add_ptrs = A_ptr + (offs_am[:, None] * a_stride_r + offs_an[None, :] * a_stride_c)
    a_add_mask = (offs_am[:, None] < M) & (offs_an[None, :] < M)
    a_add = tl.load(a_add_ptrs, mask=a_add_mask, other=0.0).to(tl.float32)

    # Apply alpha and beta
    accumulator *= alpha
    accumulator += a_add * beta

    out_dtype = C_ptr.dtype.element_ty
    output = accumulator.to(out_dtype)

    # Store block of C
    offs_cm = m_idx + tl.arange(0, BLOCK_SIZE_M)
    offs_cn = n_idx + tl.arange(0, BLOCK_SIZE_N)
    c_ptrs = C_ptr + (offs_cm[:, None] * c_stride_r + offs_cn[None, :] * c_stride_c)
    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < M)
    tl.store(c_ptrs, output, mask=c_mask)

    # Store block of C mirrored across the diagonal
    c_ptrs_t = C_ptr + (offs_cn[:, None] * c_stride_r + offs_cm[None, :] * c_stride_c)
    c_mask_t = (offs_cn[:, None] < M) & (offs_cm[None, :] < M)
    tl.store(c_ptrs_t, output.T, mask=c_mask_t)

def ba_plus_cAA(A: torch.Tensor, alpha: float, beta: float, out: torch.Tensor):
    """
    Launch Triton kernel to compute C = alpha * A @ A.T + beta * A
    """
    assert A.ndim == 2 or A.ndim == 3
    M, K = A.shape[-2:]
    assert M == K, "Input matrix must be square"
    assert out.size(-2) == M
    assert out.size(-1) == M

    batch_size = A.size(0) if A.ndim == 3 else 1
    input_batch_stride = A.stride(0) if A.ndim == 3 else 0
    output_batch_stride = out.stride(0) if out.ndim == 3 else 0

    grid = lambda meta: (
        batch_size * triton.cdiv(M, meta["BLOCK_SIZE_M"]) * triton.cdiv(M, meta["BLOCK_SIZE_N"]),
    )
    ba_plus_cAA_kernel[grid](
        A_ptr=A,
        C_ptr=out,
        M=M,
        a_stride_b=input_batch_stride,
        a_stride_r=A.stride(-2),
        a_stride_c=A.stride(-1),
        c_stride_b=output_batch_stride,
        c_stride_r=out.stride(-2),
        c_stride_c=out.stride(-1),
        alpha=alpha,
        beta=beta,
    )
    return out

# Computed for num_iters=5, safety_factor=2e-2, cushion=2
polar_express_coeffs = [
    (8.156554524902461, -22.48329292557795, 15.878769915207462),
    (4.042929935166739, -2.808917465908714, 0.5000178451051316),
    (3.8916678022926607, -2.772484153217685, 0.5060648178503393),
    (3.285753657755655, -2.3681294933425376, 0.46449024233003106),
    (2.3465413258596377, -1.7097828382687081, 0.42323551169305323)
]

@torch.compile(dynamic=False, fullgraph=True) # Must use dynamic=False or else it's much slower
def polar_express(G: torch.Tensor, split_baddbmm: bool = False):
    """
    Polar Express Sign Method: https://arxiv.org/pdf/2505.16932
    by Noah Amsel, David Persson, Christopher Musco, Robert M. Gower.
    """
    X = G.bfloat16()
    if G.size(-2) > G.size(-1):
        X = X.mT

    # Ensure spectral norm is at most 1
    X = X / (X.norm(dim=(-2, -1), keepdim=True) * (1 + 2e-2) + 1e-6)

    # Allocate buffers
    X = X.contiguous()
    A = torch.empty((*X.shape[:-1], X.size(-2)), device=X.device, dtype=X.dtype)
    B = torch.empty_like(A)
    C = torch.empty_like(X)

    # Select batched vs unbatched
    if split_baddbmm:
        BX_matmul = torch.bmm if X.ndim > 2 else torch.mm
    else:
        aX_plus_BX = torch.baddbmm if X.ndim > 2 else torch.addmm

    # Perform the iterations
    for a, b, c in polar_express_coeffs:
        XXT(X, out=A)  # A = X @ X.mT
        ba_plus_cAA(A, alpha=c, beta=b, out=B)  # B = b * A + c * A @ A

        # Referencing X twice causes pytorch to make a defensive copy,
        # resulting in a cudaMemcpyAsync in baddbmm.
        # For large matrices (i.e., the mlp weights), it's faster to split
        # the operation into two kernels to avoid this.
        if split_baddbmm:
            BX_matmul(B, X, out=C)  # C = B @ X
            C.add_(X, alpha=a)      # C = C + a*X  (in-place, X only read)
        else:
            aX_plus_BX(X, B, X, beta=a, out=C)  # C = a * X + B @ X

        X, C = C, X  # Swap references to avoid unnecessary copies

    if G.size(-2) > G.size(-1):
        X = X.mT
    return X


# -----------------------------------------------------------------------------
# Compiled helpers for NorMuon by @chrisjmccormick

@torch.compile(dynamic=False, fullgraph=True)
def cautious_wd_and_update_inplace(p, mantissa, grad, wd_tensor, lr_tensor):
    """
    Cautious weight decay + parameter update. wd_tensor and lr_tensor are 0-D CPU tensors.
    Mantissa is tracked to enable higher precision updates on bfloat16 parameters.
    bfloat16 format: 1 sign bit + 8 exponent bits + 7 mantissa bits = 16 bits total
    float32 format: 1 sign bit + 8 exponent bits + 23 mantissa bits = 32 bits total
    """
    assert p.dtype == mantissa.dtype == torch.uint16
    grad = grad.float()
    wd_factor = wd_tensor.to(torch.float32)
    lr_factor = lr_tensor.to(torch.float32)
    p_precise_raw = (p.to(torch.uint32) << 16) | mantissa.to(torch.uint32)
    p_precise = p_precise_raw.view(torch.float32)
    mask = (grad * p_precise) >= 0
    p_precise.copy_(p_precise - (p_precise * mask * wd_factor * lr_factor) - (grad * lr_factor))
    p.copy_((p_precise_raw >> 16).to(torch.uint16))
    mantissa.copy_(p_precise_raw.to(torch.uint16))

@torch.compile(dynamic=False, fullgraph=True)
def apply_normuon_variance_reduction(v_chunk, second_momentum_buffer, beta2, red_dim):
    """NorMuon variance reduction. Algebraically fuses the normalization steps to minimize memory ops."""
    v_mean = v_chunk.float().square().mean(dim=red_dim, keepdim=True)
    red_dim_size = v_chunk.size(red_dim)
    v_norm_sq = v_mean.sum(dim=(-2, -1), keepdim=True).mul_(red_dim_size)
    v_norm = v_norm_sq.sqrt_()
    second_momentum_buffer.lerp_(v_mean.to(dtype=second_momentum_buffer.dtype), 1 - beta2)
    step_size = second_momentum_buffer.clamp_min(1e-10).rsqrt_()
    scaled_sq_sum = (v_mean * red_dim_size) * step_size.float().square()
    v_norm_new = scaled_sq_sum.sum(dim=(-2, -1), keepdim=True).sqrt_()
    final_scale = step_size * (v_norm / v_norm_new.clamp_min_(1e-10))
    return v_chunk.mul_(final_scale.type_as(v_chunk))


# -----------------------------------------------------------------------------
# NorMuon optimizer

class NorMuon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    https://kellerjordan.github.io/posts/muon/

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Warning: This optimizer should not be used for the embedding layer, the final fully connected layer,
    or any {0,1}-D parameters; those should all be optimized by a standard method (e.g., AdamW).

    Differences from standard Muon:
    - Newton-Shulz is replaced with Polar Express for the orthogonalization step
    - NorMuon adds a low-rank variance estimator similar to Adafactor. https://arxiv.org/pdf/2510.05491
    - small 1D parameters handled here instead of in Adam
    - Cautious weight decay, a gated version of decoupled weight decay
    - Custom distributed sizing:
    The model stores all attn and mlp weights in the same shape, and then updates the view as
    needed on the forward pass. This enables attn and mlp weights to be contained within the same
    dist.reduce_scatter_tensor() call. The model architecture has been customized to enable
    (n_attn_layers+n_mlp_layers*2)%8==0 for batching across 8 GPUs with zero padding on mlp and attn.
    The scheduling is:
        1. reduce scatter attn/mlp round 1 (10 attn params 6 mlp params)
        2. reduce scatter attn/mlp round 2 (16 mlp params)
        3. wait on step 1, then compute update of 1 and schedule all gather
        4. wait on step 2, then compute update of 2 and schedule all gather
            GPUs receive [2 ATTN, 2 ATTN, 2 ATTN, 2 ATTN, 2 ATTN, 2 MLP, 2 MLP, 2 MLP]
            GPUs that receive params of type attn reshape before computing update
        5. wait for each all gather to complete and update params
    """
    def __init__(self, params, lr=0.02, weight_decay=0.01, momentum=0.95, beta2=0.95, custom_sizing=True):
        defaults = dict(lr=lr, weight_decay=weight_decay, momentum=momentum, beta2=beta2)
        self.world_size = dist.get_world_size() if dist.is_initialized() else 1
        # custom sizing requires 8 GPUs
        if custom_sizing and dist.get_world_size()==8:
            param_groups = self.generate_custom_param_groups(params)
        else:
            param_groups = self.generate_standard_param_groups(params)
        super().__init__(param_groups, defaults)

    def reset(self):
        # expose a reset for clearing buffers
        for group in self.param_groups:
            if "momentum_buffer" in group:
                group["momentum_buffer"].zero_()
                group["mantissa"].zero_()
                group["second_momentum_buffer"].zero_()

    def generate_standard_param_groups(self, params):
        """
        Use this method if running on less than 8 GPU or experimenting with additional attn or mlp modules.
        Creates one param group per module.
        """
        groups = defaultdict(list)
        for param in params:
            groups[param.label].append(param)

        param_groups = []
        for module_name, group_params in groups.items():
            chunk_size = (len(group_params) + self.world_size - 1) // self.world_size
            param_groups.append(dict(params=group_params, chunk_size=chunk_size))

        return param_groups

    def generate_custom_param_groups(self, params):
        """
        Implementation requires that a single GPU does not receive both attn
        and mlp params when a param group is split across GPUs.
        """
        params_list = list(params)
        module_group_order = ['attn', 'mlp']
        group_sizes = [16, 16]  # 10 attn + 6 mlp, then 16 mlp
        params_list.sort(key=lambda x: module_group_order.index(x.label))

        idx = 0
        assert len(params_list) == sum(group_sizes)
        param_groups = []
        for size in group_sizes:
            chunk_size = (size + self.world_size - 1) // self.world_size
            group_params = params_list[idx: idx + size]
            param_groups.append(dict(params=group_params, chunk_size=chunk_size))
            idx += size

        return param_groups

    def step(self):
        self.step_p1()
        self.step_p2()
        self.step_p3()
        
    @torch.no_grad()
    def step_p1(self):
        """
        Part 1: Launch distributed reduce_scatter operations for parameter groups.
        """
        rank = dist.get_rank()
        self.group_infos = []
        for group in self.param_groups:
            params: list[Tensor] = group["params"]
            if not params:
                continue

            chunk_size = group["chunk_size"]
            padded_num_params = chunk_size * self.world_size

            stacked_grads = torch.empty(
                (padded_num_params, *params[0].shape),
                dtype=params[0].dtype,
                device=params[0].device
            )
            for i, p in enumerate(params):
                stacked_grads[i].copy_(p.grad, non_blocking=True)
            if len(params) < padded_num_params:
                stacked_grads[len(params):].zero_()

            grad_chunk = torch.empty_like(stacked_grads[:chunk_size])

            reduce_future = dist.reduce_scatter_tensor(
                grad_chunk, stacked_grads, op=dist.ReduceOp.AVG, async_op=True
            ).get_future()

            self.group_infos.append(dict(grad_chunk=grad_chunk, reduce_future=reduce_future))
    
    @torch.no_grad()
    def step_p2(self):
        """
        Part 2: Compute gradient updates and launch all_gather operations
        Wait for all gather to complete for all parameter groups except final one
        """
        # Efficient distributed step by @YouJiacheng, @KonstantinWilleke, @alexrgilbert,
        # @adricarda, @tuttyfrutyee, @vdlad, @ryanyang0, @vagrawal, @varunneal, @chrisjmccormick
        rank = dist.get_rank()
        group_infos = self.group_infos
        
        self.all_gather_infos = []
        # Second pass: wait for gradients, compute updates for the local shard of parameters,
        # and launch all async all_gather operations.
        for group, info in zip(self.param_groups, group_infos):
            info["reduce_future"].wait()

            params = group["params"]
            grad_chunk = info["grad_chunk"].float()
            chunk_size = group["chunk_size"]
            padded_num_params = chunk_size * self.world_size

            start_idx = rank * chunk_size
            module_idx = start_idx if start_idx < len(params) else 0

            num_params = min(chunk_size, max(0, len(params) - start_idx))  # num params for this rank

            if "momentum_buffer" not in group:
                group["momentum_buffer"]  = torch.zeros_like(grad_chunk[:num_params], dtype=torch.float32)
                
            momentum_buffer = group["momentum_buffer"]
            # Apply momentum update to the persistent momentum buffer in-place
            momentum_buffer.lerp_(grad_chunk[:num_params], 1 - group["momentum"])
            updated_grads = grad_chunk[:num_params].lerp_(momentum_buffer, group["momentum"])

            grad_shape = updated_grads.shape
            if params[module_idx].label == 'attn':
                for p in params[module_idx:module_idx + num_params]:
                    assert p.label == 'attn'
                updated_grads = updated_grads.view(4 * grad_shape[0], grad_shape[1] // 4, grad_shape[2])

            ref_param = params[module_idx]
            param_shape = ref_param.shape

            if "second_momentum_buffer" not in group:
                group["second_momentum_buffer"] = (torch.zeros_like(updated_grads[..., :, :1], dtype=torch.float32)
                    if param_shape[-2] >= param_shape[-1] else torch.zeros_like(updated_grads[..., :1, :])
                )
            second_momentum_buffer = group["second_momentum_buffer"]

            if "param_lr_cpu" not in group:
                # Define multipliers for ALL params in this group (global, not per-shard)
                lr_mults = []
                wd_mults = []
                for p in params:
                    # Increase learning rate for modules with larger inputs than outputs.
                    # This shape check also assumes rows=input, columns=output, so take care
                    # when changing memory layouts. @chrisjmccormick
                    shape = p.shape
                    if len(shape) >= 2:
                        shape_mult = max(1.0, shape[-2] / shape[-1]) ** 0.5
                    else:
                        shape_mult = 1.0
                    lr_mults.append(shape_mult * getattr(p, "lr_mul", 1.0))
                    wd_mults.append(getattr(p, "wd_mul", 1.0))
                # Define as cpu tensors to enable Inductor constant folding
                group["param_lr_cpu"] = torch.tensor(lr_mults, dtype=torch.float32, device="cpu")
                group["param_wd_cpu"] = torch.tensor(wd_mults, dtype=torch.float32, device="cpu")

            eff_lr_all = group["param_lr_cpu"] * group["lr"]
            eff_wd_all = group["param_wd_cpu"] * group["weight_decay"] * group["lr"]

            # Slice the portion corresponding to this rank's shard
            eff_lr_cpu = eff_lr_all[module_idx:module_idx + num_params]
            eff_wd_cpu = eff_wd_all[module_idx:module_idx + num_params]

            # Compute zeropower for the entire chunk in a single, batched call.
            if num_params == 0:
                v_chunk = updated_grads
            else:
                v_chunk = polar_express(updated_grads, split_baddbmm=(ref_param.label == 'mlp'))

            # Note that the head orientation in O is transposed relative to QKV, so red_dim
            # is 'incorrect' for O. However, correcting this showed no improvement. @chrisjmccormick
            red_dim = -1 if param_shape[-2] >= param_shape[-1] else -2

            v_chunk = apply_normuon_variance_reduction(
                v_chunk, second_momentum_buffer, group["beta2"], red_dim
            )

            v_chunk = v_chunk.view(grad_shape)

            # # "Cautious" weight decay (https://arxiv.org/abs/2510.12402)
            updated_params = torch.empty_like(grad_chunk, dtype=torch.bfloat16)
            if num_params > 0:
                # Work on a stacked copy to avoid touching original params
                param_chunk = torch.stack(params[module_idx:module_idx + num_params])

                if "mantissa" not in group:
                    group["mantissa"] = torch.zeros_like(param_chunk, dtype=torch.uint16)
                mantissa = group["mantissa"]

                for local_idx in range(num_params):
                    cautious_wd_and_update_inplace(
                        param_chunk[local_idx].view(torch.uint16),
                        mantissa[local_idx],
                        v_chunk[local_idx],
                        eff_wd_cpu[local_idx],
                        eff_lr_cpu[local_idx]
                    )
            else:
                param_chunk = torch.zeros_like(v_chunk)

            updated_params[:num_params].copy_(param_chunk)
            if num_params < chunk_size:
                updated_params[num_params:].zero_()

            stacked_params = torch.empty(
                (padded_num_params, *param_shape),
                dtype=updated_params.dtype,
                device=updated_params.device,
            )

            gather_future = dist.all_gather_into_tensor(
                stacked_params, updated_params, async_op=True
            ).get_future()

            self.all_gather_infos.append(
                {
                    "gather_future": gather_future,
                    "stacked_params": stacked_params,
                    "orig_params": params,
                }
            )

        # Final pass: wait for all_gather to complete for all except final and copy results back into original parameter tensors.
        for info in self.all_gather_infos[:-1]:
            info["gather_future"].wait()
            stacked_params = info["stacked_params"]
            orig_params = info["orig_params"]

            unstacked_params = torch.unbind(stacked_params)
            for i, p in enumerate(orig_params):
                p.copy_(unstacked_params[i], non_blocking=True)

    @torch.no_grad()
    def step_p3(self):
        """
        Part 3: Wait for final all gather to complete and copy results back into original parameter tensors
        """
        info = self.all_gather_infos[-1]
        info["gather_future"].wait()
        stacked_params = info["stacked_params"]
        orig_params = info["orig_params"]

        unstacked_params = torch.unbind(stacked_params)
        for i, p in enumerate(orig_params):
            p.copy_(unstacked_params[i], non_blocking=True)


class DistAdam(torch.optim.Optimizer):
    def __init__(self, params, label_order: list[str], betas: list[list[float]], lr: float = 1e-3, eps: float = 1e-8, weight_decay: float = 0.01):
        self.world_size = dist.get_world_size() if dist.is_initialized() else 1
        defaults = dict(lr=lr, eps=eps, weight_decay=weight_decay)
        params = list(params)
        # Group by label, with explicit ordering for execution control.
        params_by_label = defaultdict(list)
        for p in params:
            params_by_label[getattr(p, 'label', None)].append(p)
        param_groups = []
        for idx, label in enumerate(label_order):
            if label in params_by_label:
                param_groups.append(dict(params=params_by_label[label], betas=betas[idx]))
        # include any unlabeled params at the end (processed last)
        if None in params_by_label:
            param_groups.append(dict(params=params_by_label[None]))
        super().__init__(param_groups, defaults)
        # init state: small params (numel < 1024) use full-sized state, others use sharded
        for p in params:
            chunk = p if p.numel() < 1024 else p[:p.size(0) // self.world_size]
            exp_avg = torch.zeros_like(chunk, dtype=torch.float32, device=p.device)
            self.state[p] = dict(step=0, exp_avg=exp_avg, exp_avg_sq=torch.zeros_like(exp_avg))

        # tag the final param for optimizer pipelining, run all gather after muon copy
        param_groups[-1]['params'][-1].is_final_param = True
        
        # DistributedAdam implementation by @vagrawal, @akash5474
        self.should_sync = False
        self._reduce_scatter_hooks = []
        self._reduce_scatter_futures = {}
        # 0-D CPU tensors to avoid recompilation in _update_step
        self._step_size_t = torch.tensor(0.0, dtype=torch.float32, device="cpu")
        self._eff_wd_t = torch.tensor(0.0, dtype=torch.float32, device="cpu")
        self.register_backward_hooks()

    def register_backward_hooks(self):
        for group in self.param_groups:
            for param in group["params"]:
                self._reduce_scatter_hooks.append(param.register_post_accumulate_grad_hook(self._sync_gradient))

    def load_state_dict(self, state_dict):
        """Override to preserve optimizer state dtypes (avoid BFloat16->Float32 cast that causes recompilation)."""
        # Save original state dtypes before loading
        original_dtypes = {}
        for p, s in self.state.items():
            original_dtypes[p] = {k: v.dtype for k, v in s.items() if isinstance(v, torch.Tensor)}
        
        # Call parent load_state_dict (which may cast dtypes to match param dtype)
        super().load_state_dict(state_dict)
        
        # Restore original dtypes
        for p, s in self.state.items():
            if p in original_dtypes:
                for k, v in s.items():
                    if isinstance(v, torch.Tensor) and k in original_dtypes[p]:
                        if v.dtype != original_dtypes[p][k]:
                            s[k] = v.to(original_dtypes[p][k])

    @torch.no_grad()
    def _sync_gradient(self, param):
        if not self.should_sync:
            return

        grad = param.grad
        if param.numel() < 1024:
            # Small params: use all_reduce (no scatter/gather needed)
            self._reduce_scatter_futures[param] = (
                dist.all_reduce(grad, op=dist.ReduceOp.AVG, async_op=True).get_future(),
                grad
            )
        else:
            rank_size = grad.shape[0] // self.world_size
            if grad is not None:
                grad_slice = torch.empty_like(grad[:rank_size])
                self._reduce_scatter_futures[param] = (
                    dist.reduce_scatter_tensor(grad_slice, grad, op=dist.ReduceOp.AVG, async_op=True).get_future(),
                    grad_slice
                )

    def copy_lm_to_embed(self):
        # run at 2/3 of training
        lm_head = self.param_groups[0]['params'][0]
        embed = self.param_groups[-2]['params'][0]
        lm_head_state = self.state[lm_head]
        embed_state = self.state[embed]
        embed_state['step'] = lm_head_state['step']
        embed_state['exp_avg'] = lm_head_state['exp_avg'].clone()
        embed_state['exp_avg_sq'] = lm_head_state['exp_avg_sq'].clone()
        embed.data.copy_(lm_head.data)

    @staticmethod
    @torch.compile(dynamic=False, fullgraph=True)
    def _update_step(p_slice, g_slice, exp_avg, exp_avg_sq, beta1, beta2, eps, step_size_t, eff_wd_t):
        """Compiled Adam update step. step_size_t and eff_wd_t are 0-D CPU tensors to avoid recompilation."""
        exp_avg.mul_(beta1).add_(g_slice, alpha=1 - beta1)  # exp_avg = beta1 * exp_avg + (1 - beta1) * g_slice
        exp_avg_sq.mul_(beta2).addcmul_(g_slice, g_slice, value=1 - beta2)  # exp_avg_sq = beta2 * exp_avg_sq + (1 - beta2) * g_slice^2
        # compute step
        update = exp_avg.div(exp_avg_sq.sqrt().add_(eps)).mul_(step_size_t)  # update = (exp_avg / (sqrt(exp_avg_sq) + eps)) * step_size
        # cautious weight decay
        mask = (update * p_slice) > 0
        update.addcmul_(p_slice, mask, value=eff_wd_t)  # update += eff_wd_t * p_slice * mask
        p_slice.add_(other=update, alpha=-1.0)  # p_slice -= update

    @torch.no_grad()
    def step(self, muon_opt):
        muon_opt.step_p1()
        rank = dist.get_rank()
        all_gather_futures: list[torch.Future] = []

        last_param = None
        last_p_slice = None
        for group in self.param_groups:      
            beta1, beta2 = group['betas']
            eps = group['eps']
            wd = group['weight_decay']
            for param in group['params']:
                if param not in self._reduce_scatter_futures:
                    continue

                fut, g_slice = self._reduce_scatter_futures[param]
                fut.wait()

                is_small = param.numel() < 1024
                if is_small:
                    # Small params: g_slice is actually full grad, p_slice is full param
                    p_slice = param
                else:
                    rank_size = param.shape[0] // self.world_size
                    p_slice = param[rank * rank_size:(rank + 1) * rank_size]

                lr = group['lr'] * getattr(param, "lr_mul", 1.0)
                state = self.state[param]
                state["step"] += 1
                t = state["step"]
                
                # Pre-compute changing values as 0-D CPU tensors to avoid recompilation.
                # `.fill_(value)` is the same as "= value", but doesn't change the tensor object.
                bias1, bias2 = 1 - beta1 ** t, 1 - beta2 ** t
                self._step_size_t.fill_(lr * (bias2 ** 0.5 / bias1))
                self._eff_wd_t.fill_(lr * lr * wd * getattr(param, "wd_mul", 1.0)) # `lr` included twice to serve as weight decay schedule.

                DistAdam._update_step(p_slice, g_slice, state["exp_avg"], state["exp_avg_sq"],
                                      beta1, beta2, eps, self._step_size_t, self._eff_wd_t)

                if not is_small:
                    if getattr(param, "is_final_param", False):
                        last_param = param
                        last_p_slice = p_slice
                    else:
                        all_gather_futures.append(dist.all_gather_into_tensor(param, p_slice, async_op=True).get_future())
        self._reduce_scatter_futures.clear()

        muon_opt.step_p2()
        torch.futures.collect_all(all_gather_futures).wait()

        if last_param is not None:
            last_all_gather_future = dist.all_gather_into_tensor(last_param, last_p_slice, async_op=True).get_future()
        muon_opt.step_p3()
        torch.futures.collect_all([last_all_gather_future]).wait()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the model

def norm(x: Tensor):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):
    def __init__(self, in_features: int, out_features: int, use_fp8=False, x_s=1.0, w_s=1.0, grad_s=1.0):
        super().__init__(in_features, out_features, bias=False)
        self.use_fp8 = use_fp8
        self.x_s = x_s
        self.w_s = w_s
        self.grad_s = grad_s

    def reset_parameters(self) -> None:
        with torch.no_grad():
            self.weight.zero_()  # @Grad62304977 and others

    def forward(self, x: Tensor):
        if self.use_fp8 and self.training:
            _x = x.flatten(0, -2)
            out: Tensor = torch.ops.nanogpt.mm(_x, self.weight, x_s=self.x_s, w_s=self.w_s, grad_s=self.grad_s)[0]
            return out.reshape(*x.shape[:-1], -1)
        else:
            return F.linear(x, self.weight.type_as(x))


# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the model

class Yarn(nn.Module):
    def __init__(self, head_dim, max_seq_len):
        super().__init__()
        self.head_dim = head_dim
        self.max_seq_len = max_seq_len
        self.reset()

    def rotary(self, x_BTHD):
        assert self.factor1.size(0) >= x_BTHD.size(-3)
        factor1, factor2 = (
            self.factor1[None, : x_BTHD.size(-3), None, :],
            self.factor2[None, : x_BTHD.size(-3), None, :],
        )
        x_flip = x_BTHD.view(*x_BTHD.shape[:-1], x_BTHD.shape[-1] // 2, 2).flip(-1).view(x_BTHD.shape)
        return factor1 * x_BTHD + factor2 * x_flip

    def reset(self):
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=self.head_dim//4, dtype=torch.float32, device=device)
        angular_freq = angular_freq.repeat_interleave(2)
        # half-truncate RoPE by @YouJiacheng (w/ base freq tuning)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(self.head_dim//2)])
        t = torch.arange(2*self.max_seq_len, dtype=torch.float32, device=device)
        theta = torch.outer(t, angular_freq)
        self.factor1 = nn.Buffer(
            theta.cos().to(torch.bfloat16), persistent=False
        )
        self.factor2 = nn.Buffer(
            theta.sin().to(torch.bfloat16), persistent=False
        )
        self.factor2[..., 1::2] *= -1
        self.angular_freq = angular_freq
        # start with 0.1, inspired by 0.12 from @leloykun and learnable scalars used by @brendanh0gan https://x.com/hi_tysam/status/1879693583898591283
        self.attn_scale = 0.1

    def apply(self, old_window: int, new_window: int, alpha: int=1, beta: int=32):
        rotations = args.block_size * old_window * self.angular_freq / (2 * torch.pi)
        scaling_factor = old_window / new_window
        interpolation_weight = torch.clamp((rotations - alpha) / (beta - alpha), 0, 1)
        self.angular_freq *= scaling_factor + interpolation_weight * (1 - scaling_factor)
        t = torch.arange(2*self.max_seq_len, dtype=torch.float32, device=self.angular_freq.device)
        theta = torch.outer(t, self.angular_freq)
        self.factor1.copy_(theta.cos())
        self.factor2.copy_(theta.sin())
        self.factor2[..., 1::2] *= -1
        self.attn_scale *= 0.2 * math.log(new_window / old_window) + 1

class YarnPairedHead(nn.Module):
    def __init__(self, head_dim, max_seq_len):
        super().__init__()
        self.head_dim = head_dim
        self.max_seq_len = max_seq_len
        self.reset()

    def rotary(self, x_BTHD):
        assert self.factor1.size(0) >= x_BTHD.size(-3)
        factor1, factor2 = (
            self.factor1[None, : x_BTHD.size(-3), None, :],
            self.factor2[None, : x_BTHD.size(-3), None, :],
        )
        x_flip = x_BTHD.view(*x_BTHD.shape[:-1], x_BTHD.shape[-1] // 2, 2).flip(-1).view(x_BTHD.shape)
        return factor1 * x_BTHD + factor2 * x_flip

    def reset(self):
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=self.head_dim//4, dtype=torch.float32, device=device)
        angular_freq = angular_freq.repeat_interleave(2)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(self.head_dim//2)])
        t = torch.arange(2*self.max_seq_len, dtype=torch.float32, device=device)
        t_even = 2 * t
        t_odd = 2 * t + 1
        theta1 = torch.outer(t_even, angular_freq)
        theta2 = torch.outer(t_odd, angular_freq)
        self.factor1 = nn.Buffer(
            torch.cat((theta1.cos(),theta2.cos()), dim=-1).to(torch.bfloat16), 
            persistent=False
        )
        self.factor2 = nn.Buffer(
            torch.cat((theta1.sin(),theta2.sin()), dim=-1).to(torch.bfloat16), 
            persistent=False
        )
        self.factor2[..., 1::2] *= -1
        self.angular_freq = angular_freq
        # start with 0.1, inspired by 0.12 from @leloykun and learnable scalars used by @brendanh0gan https://x.com/hi_tysam/status/1879693583898591283
        self.attn_scale = 0.1

    def apply(self, old_window: int, new_window: int, alpha: int=1, beta: int=32):
        rotations = args.block_size * old_window * self.angular_freq / (2 * torch.pi)
        scaling_factor = old_window / new_window
        interpolation_weight = torch.clamp((rotations - alpha) / (beta - alpha), 0, 1)
        self.angular_freq *= scaling_factor + interpolation_weight * (1 - scaling_factor)
        t = torch.arange(2*self.max_seq_len, dtype=torch.float32, device=self.angular_freq.device)
        t_even = 2 * t
        t_odd = 2 * t + 1
        theta1 = torch.outer(t_even, self.angular_freq)
        theta2 = torch.outer(t_odd, self.angular_freq)
        self.factor1.copy_(torch.cat((theta1.cos(),theta2.cos()), dim=-1))
        self.factor2.copy_( torch.cat((theta1.sin(),theta2.sin()), dim=-1))
        self.factor2[..., 1::2] *= -1
        self.attn_scale *= 0.2 * math.log(new_window / old_window) + 1

@dataclass
class AttnArgs:
    ve: torch.Tensor
    sa_lambdas: torch.Tensor
    seqlens: torch.Tensor
    bm_size: int
    yarn: Yarn
    key_offset: bool
    attn_gate_w: torch.Tensor
    ve_gate_w: torch.Tensor

flash_attn_interface = get_kernel('varunneal/flash-attention-3').flash_attn_interface

class CausalSelfAttention(nn.Module):
    def __init__(self, dim: int, head_dim: int, num_heads: int, layer_idx: int):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = head_dim
        self.dim = dim
        self.hdim = num_heads * head_dim

        assert self.hdim == self.dim, "num_heads * head_dim must equal model_dim"
        std = self.dim ** -0.5
        bound = (3 ** 0.5) * std # improved init scale by @YouJiacheng
        # merged QKVO weights: suggested by many, implemented by @fernbear.bsky.social, and further improved by @YouJiacheng
        # https://x.com/hi_tysam/status/1879699187107033311
        # Simplified layout by @chrisjmccormick
        self.qkvo_w = nn.Parameter(torch.empty(self.dim * 4, self.hdim, dtype=torch.bfloat16))
        # label all modules for explicit optimizer grouping
        self.qkvo_w.label = 'attn'

        with torch.no_grad():
            self.qkvo_w[:self.dim * 3].uniform_(-bound, bound)  # init QKV weights
            self.qkvo_w[self.dim * 3:].zero_()  # init O weights to zero

    def forward(self, x: Tensor, attn_args: AttnArgs):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, "varlen sequences requires B == 1"
        assert T % 16 == 0
        # unpack attention args
        yarn = attn_args.yarn
        ve, sa_lambdas, key_offset = attn_args.ve, attn_args.sa_lambdas, attn_args.key_offset
        seqlens, bm_size = attn_args.seqlens, attn_args.bm_size
        # sparse gated attention to enable context based no-op by @classiclarryd
        # only include gates on layers with value embeds used on forward pass
        attn_gate_w, ve_gate_w = attn_args.attn_gate_w, attn_args.ve_gate_w

        q, k, v = F.linear(x, sa_lambdas[0] * self.qkvo_w[:self.dim * 3].type_as(x)).view(B, T, 3 * self.num_heads, self.head_dim).chunk(3, dim=-2)
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = yarn.rotary(q), yarn.rotary(k)
        if key_offset:
            # shift keys forward for the stationary head dims. Enables 1-layer induction.
            k[:, 1:, :, self.head_dim // 4:self.head_dim // 2] = k[:, :-1, :, self.head_dim // 4:self.head_dim // 2]
            k[:, 1:, :, 3 * self.head_dim // 4:] = k[:, :-1, :, 3 * self.head_dim // 4:]
        if ve is not None:
            ve_gate_out = 2 * torch.sigmoid(F.linear(x[..., :12], ve_gate_w)).view(B, T, self.num_heads, 1)
            v = v + ve_gate_out * ve.view_as(v) # @ KoszarskyB & @Grad62304977

        max_len = args.train_max_seq_len if self.training else (args.val_batch_size // (grad_accum_steps * world_size))

        # use flash_attn over flex_attn @varunneal. flash_attn_varlen suggested by @YouJiacheng
        y = flash_attn_interface.flash_attn_varlen_func(q[0], k[0], v[0], cu_seqlens_q=seqlens, cu_seqlens_k=seqlens,
                                                        max_seqlen_q=max_len, max_seqlen_k=max_len,
                                                        causal=True, softmax_scale=yarn.attn_scale, window_size=(bm_size, 0))
        y = y.view(B, T, self.num_heads, self.head_dim)
        y = y * torch.sigmoid(F.linear(x[..., :12], attn_gate_w)).view(B, T, self.num_heads, 1)
        y = y.contiguous().view(B, T, self.num_heads * self.head_dim) # re-assemble all head outputs side by side
        y = F.linear(y, sa_lambdas[1] * self.qkvo_w[self.dim * 3:].type_as(y))  # sa_lambdas[1] pre-multiplied to O @shenberg
        return y

class PairedHeadCausalSelfAttention(nn.Module):
    """
    Pairs up attention heads such that queries from head 1 can attend to keys in head 2, and vice-versa.
    Implemented by interleaving the k, q, and v for pairs of heads to form twice as long sequences
    EG [k1_h1, k2_h1, k3_h1], [k1_h2, k2_h2, k3_h2] -> [k1_h1, k1_h2, k2_h1, k2_h2, k3_h1, k3_h2], repeat for q and v
    """
    def __init__(self, dim: int, head_dim: int, num_heads: int, layer_idx: int):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = head_dim
        self.dim = dim
        self.hdim = num_heads * head_dim

        assert self.hdim == self.dim, "num_heads * head_dim must equal model_dim"
        std = self.dim ** -0.5
        bound = (3 ** 0.5) * std
        self.qkvo_w = nn.Parameter(torch.empty(self.dim * 4, self.hdim, dtype=torch.bfloat16))
        self.qkvo_w.label = 'attn'

        with torch.no_grad():
            self.qkvo_w[:self.dim * 3].uniform_(-bound, bound)
            self.qkvo_w[self.dim * 3:].zero_()

    def forward(self, x: Tensor, attn_args: AttnArgs):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, "varlen sequences requires B == 1"
        assert T % 16 == 0
        # unpack attention args
        yarn = attn_args.yarn
        ve, sa_lambdas = attn_args.ve, attn_args.sa_lambdas
        seqlens, bm_size = attn_args.seqlens, attn_args.bm_size
        attn_gate_w, ve_gate_w = attn_args.attn_gate_w, attn_args.ve_gate_w

        q, k, v = F.linear(x, sa_lambdas[0] * self.qkvo_w[:self.dim * 3].type_as(x)).view(B, T, 3 * self.num_heads, self.head_dim).chunk(3, dim=-2)
        q, k = norm(q), norm(k)

        # delay q,k reshape until rotary makes data contiguous, to enable view (non-copy)
        q = q.view(B, T, self.num_heads // 2, self.head_dim * 2)
        k = k.view(B, T, self.num_heads // 2, self.head_dim * 2)
        v = v.reshape(B, T*2, self.num_heads//2, self.head_dim)

        q, k = yarn.rotary(q), yarn.rotary(k)

        q = q.view(B, T*2, self.num_heads//2, self.head_dim)
        k = k.view(B, T*2, self.num_heads//2, self.head_dim)

        if ve is not None:
            ve_gate_out = 2 * torch.sigmoid(F.linear(x[..., :12], ve_gate_w)).view(B, T*2, self.num_heads//2, 1)
            v = v + ve_gate_out * ve.view_as(v)

        max_len = args.train_max_seq_len if self.training else (args.val_batch_size // (grad_accum_steps * world_size))

        # paired head correction
        seqlens = 2 * seqlens
        max_len = 2 * max_len

        y = flash_attn_interface.flash_attn_varlen_func(q[0], k[0], v[0], cu_seqlens_q=seqlens, cu_seqlens_k=seqlens,
                                                        max_seqlen_q=max_len, max_seqlen_k=max_len,
                                                        causal=True, softmax_scale=yarn.attn_scale, window_size=(bm_size, 0))
        y = y.view(B, T, self.num_heads, self.head_dim)
        y = y * torch.sigmoid(F.linear(x[..., :12], attn_gate_w)).view(B, T, self.num_heads, 1)
        y = y.contiguous().view(B, T, self.num_heads * self.head_dim)
        y = F.linear(y, sa_lambdas[1] * self.qkvo_w[self.dim * 3:].type_as(y))
        return y

class MLP(nn.Module):
    def __init__(self, dim: int):
        super().__init__()
        hdim = 4 * dim
        # Transposed layout to match attention weights
        self.c_fc = nn.Parameter(torch.empty(hdim, dim, dtype=torch.bfloat16))
        self.c_proj = nn.Parameter(torch.empty(hdim, dim, dtype=torch.bfloat16))
        # label all modules for explicit optimizer grouping
        self.c_fc.label = 'mlp'
        self.c_proj.label = 'mlp'
        self.c_proj.lr_mul = 2.

        std = 0.5 * (dim ** -0.5)
        bound = (3 ** 0.5) * std # improved init scale by @YouJiacheng
        with torch.no_grad():
            self.c_fc.uniform_(-bound, bound)
            self.c_proj.zero_() # zero init suggested by @Grad62304977

    def forward(self, x: Tensor):
        x = F.linear(x, self.c_fc.type_as(x))
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = F.linear(x, self.c_proj.T.type_as(x))
        return x

class Block(nn.Module):
    def __init__(self, dim: int, head_dim: int, num_heads: int, layer_idx: int, use_paired_head: bool):
        super().__init__()
        # skip attention of blocks.6 (the 7th layer) by @YouJiacheng
        if use_paired_head:
            self.attn = PairedHeadCausalSelfAttention(dim, head_dim, num_heads, layer_idx)
        else:
            self.attn = CausalSelfAttention(dim, head_dim, num_heads, layer_idx) if layer_idx != 6 else None
        # skip MLP blocks for first MLP layer by @EmelyanenkoK
        self.mlp = MLP(dim)

    def forward(self, x: Tensor, attn_args: AttnArgs):
        if self.attn is not None:
            x = x + self.attn(norm(x), attn_args)
        if self.mlp is not None:
            x = x + self.mlp(norm(x))
        return x

# -----------------------------------------------------------------------------
# The main model

def next_multiple_of_n(v: float | int, *, n: int):
    return next(x for x in range(n, int(v) + 1 + n, n) if x >= v)

@dataclass
class ForwardScheduleConfig:
    mtp_weights: torch.Tensor
    ws_short: int
    ws_long: int

class GPT(nn.Module):
    def __init__(self, vocab_size: int, num_layers: int, num_heads: int, head_dim: int, model_dim: int, max_seq_len: int, use_malbo: bool):
        super().__init__()
        self.num_layers = num_layers
        vocab_size = next_multiple_of_n(vocab_size, n=128)

        self.smear_gate = CastedLinear(12, 1)
        self.smear_gate.weight.label = 'smear_gate'
        self.smear_gate.weight.lr_mul = 0.01
        self.smear_gate.weight.wd_mul = 0.0

        self.skip_gate = CastedLinear(12, 1)
        self.skip_gate.weight.label = 'skip_gate'
        self.skip_gate.weight.lr_mul = 0.05
        self.skip_gate.weight.wd_mul = 0.0

        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual implementation following https://arxiv.org/abs/2410.17897
        # value embedding code simplification inspired by @ragulpr https://github.com/KellerJordan/modded-nanogpt/pull/78
        self.value_embeds = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])
        for embed in self.value_embeds:
            nn.init.zeros_(embed.weight)
        for ve in self.value_embeds:
            ve.weight.label = 'value_embed'
        
        # parameter banks for attention and value embedding gate weights
        self.attn_gate_bank = nn.Parameter(torch.zeros(10, num_heads, 12)) # 10 layers
        self.attn_gate_bank.label = 'attn_gate_bank'
        self.ve_gate_bank = nn.Parameter(torch.zeros(5, num_heads, 12)) # 5 layers
        self.ve_gate_bank.label = 've_gate_bank'

        self.paired_head_layers = [0, 2, 5, 9]
        self.blocks = nn.ModuleList([Block(model_dim, head_dim, num_heads, i, i in self.paired_head_layers) for i in range(num_layers)])
        self.yarn = Yarn(head_dim, max_seq_len)
        self.yarn_paired_head = YarnPairedHead(head_dim, max_seq_len)
        # there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency.
        # suggested to me by @Grad62304977. this originates from Karpathy's experiments.
        use_fp8 = not os.environ.get("DISABLE_FP8", False)

        self.lm_head = CastedLinear(model_dim, vocab_size, use_fp8=use_fp8, x_s=100/448, w_s=1.6/448, grad_s=0.75/448)
        nn.init.normal_(self.lm_head.weight, mean=0, std=0.005)
        self.lm_head.weight.label = 'lm_head'

        self.embed = nn.Embedding(vocab_size, model_dim)
        self.embed.weight.label = 'embed'

        # x0_lambdas separated out for different optimizer treatment (no beta smoothing)
        self.x0_lambdas = nn.Parameter(torch.zeros(num_layers))
        self.x0_lambdas.label = 'x0_lambdas'
        self.x0_lambdas.lr_mul = 5.0
        self.x0_lambdas.wd_mul = 0.0

        pad = (-num_layers * 3 - 3) % dist.get_world_size()  # updated: 3*num_layers instead of 4*
        self.scalars = nn.Parameter(
            torch.cat(
                [
                    1.1 * torch.ones(num_layers),  # resid lambdas. 1.1 init such that layer i weight is i^(num_layers-i).
                    *[torch.tensor([0.5, 1.0]) for _ in range(num_layers)],  # SA lambdas
                    torch.zeros(1), # smear_lambda
                    0.5*torch.ones(1), # backout_lambda
                    -1.5 * torch.ones(1),  # skip_lambda -> (-1.5)  0.18
                    torch.ones(pad),
                ]
            )
        )

        self.scalars.label = 'scalars'
        # set learning rates
        for param in self.value_embeds.parameters():
            param.lr_mul = 75.
            param.wd_mul = 5.
        for param in self.embed.parameters():
            param.wd_mul = 150.
        for param in self.lm_head.parameters():
            param.wd_mul = 150.
        self.scalars.lr_mul = 5.0
        self.scalars.wd_mul = 0.0

        self.split_embed = False

        self.use_malbo = use_malbo

    def forward(self, input_seq: Tensor, target_seq: Tensor, seqlens: Tensor, schedule_cfg: ForwardScheduleConfig):
        assert input_seq.ndim == 1

        # unpack schedule_cfg
        mtp_weights, ws_short, ws_long = schedule_cfg.mtp_weights, schedule_cfg.ws_short, schedule_cfg.ws_long

        # set configs
        skip_connections = []
        skip_in = [3] # long attention window on layer 3
        skip_out = [6] # no attn op on layer 6
        x_backout = None
        backout_layer = 7

        # set lambdas
        resid_lambdas = self.scalars[: 1 * self.num_layers]
        x0_lambdas = self.x0_lambdas
        sa_lambdas = self.scalars[1 * self.num_layers: 3 * self.num_layers].view(-1, 2)
        smear_lambda = self.scalars[3 * self.num_layers]
        backout_lambda = self.scalars[3 * self.num_layers+1]
        skip_lambda = self.scalars[3 * self.num_layers+2]

        # set block masks and key shift
        short_bm = ws_short * args.block_size
        long_bm = ws_long * args.block_size
        bm_sizes = [short_bm, short_bm, short_bm, long_bm, short_bm, short_bm, None, short_bm, short_bm, short_bm, long_bm]
        assert len(bm_sizes) == self.num_layers
        key_offset = [b==long_bm for b in bm_sizes] # apply partial key offset to long windows

        # weight-tied: use lm_head.weight for embedding lookup (or separate embed after split)
        if self.split_embed:
            x = self.embed(input_seq)
        else:
            x = F.embedding(input_seq, self.lm_head.weight)
        ve = [value_embed(input_seq) for value_embed in self.value_embeds]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        # dropping first layer updates this to .12 ... 012
        ve = [ve[1], ve[2]] + [None] * (self.num_layers - 5) + [ve[0], ve[1], ve[2]]
        assert len(ve) == self.num_layers

        # smear token embed forward 1 position @classiclarryd
        smear_gate_out = smear_lambda * torch.sigmoid(self.smear_gate(x[1:, :self.smear_gate.weight.size(-1)]))
        x = torch.cat([x[:1], x[1:] + smear_gate_out * x[:-1]])
        x = x0 = norm(x[None])

        # unbind gate banks to avoid select_backwards kernel
        ag = [w.bfloat16() for w in self.attn_gate_bank.unbind(0)] 
        veg = [w.bfloat16() for w in self.ve_gate_bank.unbind(0)]
        attn_gates = ag[:6] + [None] + ag[6:]
        ve_gates = [veg[0], veg[1]] + [None] * (self.num_layers - 5) + [veg[2], veg[3], veg[4]]
        assert len(attn_gates) == self.num_layers
        assert len(ve_gates) == self.num_layers

        for i in range(self.num_layers):
            yarn = self.yarn_paired_head if i in self.paired_head_layers else self.yarn
            attn_args = AttnArgs(
                ve=ve[i],
                sa_lambdas=sa_lambdas[i],
                seqlens=seqlens,
                bm_size=bm_sizes[i],
                yarn=yarn,
                key_offset=key_offset[i],
                attn_gate_w=attn_gates[i],
                ve_gate_w=ve_gates[i]
            )
            if i in skip_out:
                skip_gate_out = torch.sigmoid(skip_lambda) * 2 * torch.sigmoid(self.skip_gate(x0[..., :self.skip_gate.weight.size(-1)]))
                x = x + skip_gate_out * skip_connections.pop()
            if i == 0:
                x = (resid_lambdas[0] + x0_lambdas[0]) * x
            else:
                x = resid_lambdas[i] * x + x0_lambdas[i] * x0
            x = self.blocks[i](x, attn_args)
            if i in skip_in:
                skip_connections.append(x)
            if i == backout_layer:
                x_backout = x

        # back out contributions from first 7 layers that are only required for downstream context and not direct prediction
        x -= backout_lambda * x_backout
        x = norm(x)
        logits = self.lm_head(x)
        # @Grad62304977 added tanh softcapping following Gemma 2 paper, @KoszarskyB reduced it from 30 to 15
        # @YouJiacheng shifted it by +15 (2*sigmoid(2*x)=tanh(x)+1). @classiclarryd updated to 23*sigmoid((logits+5)/7.5)
        logits = 23 * torch.sigmoid((logits + 5) / 7.5)
        logits_for_loss = logits.float() if not self.training else logits

        n_predict = mtp_weights.size(0) if mtp_weights is not None else 1
        if self.training and n_predict > 1:
            # Multi-token prediction: take loss of the weighted average of next n_predict tokens
            logits_flat = logits_for_loss.view(-1, logits_for_loss.size(-1))
            idx = F.pad(target_seq, (0, n_predict - 1)).unfold(0, n_predict, 1)  # [T, n_predict] of shifted targets
            target_logits = logits_flat.gather(1, idx)
            cross_entropy = torch.logsumexp(logits_flat, dim=-1).unsqueeze(1) - target_logits
            for k in range(1, n_predict):  # zero out preds past end of sequence
                cross_entropy[-k:, k] = 0

            loss = (cross_entropy * mtp_weights).sum()
            if self.use_malbo:
                T, K = logits_flat.shape
                with torch.no_grad():
                    vhat, kappa, gamma = compute_malbo_parameters(cross_entropy.float().T, K)
                    weights_transposed = kappa * gamma

                malbo_loss = T * (cross_entropy * weights_transposed.T * mtp_weights).sum()

                if not torch.isfinite(loss) or not torch.isfinite(malbo_loss):
                    raise RuntimeError(f"Non-finite loss (1): {loss} {malbo_loss}")
            else:
                malbo_loss = loss
        elif self.training:
            if self.use_malbo:
                logits_flat = logits_for_loss.view(-1, logits_for_loss.size(-1))
                T, K = logits_flat.shape
                cross_entropy = F.cross_entropy(logits_flat, target_seq, reduction="none")
                loss = cross_entropy.sum()

                with torch.no_grad():
                    vhat, kappa, gamma = compute_malbo_parameters(cross_entropy.float().unsqueeze(0), K)
                    weights = (kappa * gamma).squeeze(0)

                malbo_loss = T * (weights * cross_entropy).sum()

                if not torch.isfinite(loss) or not torch.isfinite(malbo_loss):
                    raise RuntimeError(f"Non-finite loss (2): {loss} {malbo_loss}")
            else:
                loss = F.cross_entropy(logits_for_loss.view(-1, logits_for_loss.size(-1)), target_seq, reduction="sum")
                malbo_loss = loss
        else:
            if self.use_malbo:
                K = logits_for_loss.size(-1)
                cross_entropy = F.cross_entropy(logits_for_loss.view(-1, logits_for_loss.size(-1)), target_seq, reduction="none")
                loss = cross_entropy.mean()

                with torch.no_grad():
                    vhat, kappa, gamma = compute_malbo_parameters(cross_entropy.float().unsqueeze(0), K)
                    weights = (kappa * gamma).squeeze(0)

                malbo_loss = (weights * cross_entropy).sum()

                if not torch.isfinite(loss) or not torch.isfinite(malbo_loss):
                    raise RuntimeError(f"Non-finite loss (3): {loss} {malbo_loss}")
            else:
                loss = F.cross_entropy(logits_for_loss.view(-1, logits_for_loss.size(-1)), target_seq, reduction="mean")
                malbo_loss = loss

        return loss, malbo_loss

# -----------------------------------------------------------------------------
# Distributed data loader

def _load_data_shard(file: Path):
    header = torch.from_file(str(file), False, 256, dtype=torch.int32) # header is 256 int32
    assert header[0] == 20240520, "magic number mismatch in the data .bin file"
    assert header[1] == 1, "unsupported version"
    num_tokens = int(header[2]) # number of tokens (claimed)
    with file.open("rb", buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, "number of tokens read does not match header"
    return tokens

BOS_ID = 50256

class BOSFinder:
    # Helper for getting sequences that start at the beginning of documents by @varunneal based on work by @classiclarryd
    def __init__(self, tokens: Tensor, world_size: int = 1, quickload: bool = False):
        # Precompute BOS positions once per shard
        self.tokens=tokens
        self.size = tokens.numel()
        self.quickload = quickload
        if quickload:
            # only scan first 4 million tokens, then kickoff async thread to scan rest
            self.bos_idx = (tokens[:4_000_000] == BOS_ID).nonzero(as_tuple=True)[0].to(torch.int64).cpu().numpy()
            self.thread = None
            self.ready = threading.Event()
            self.start()
        else:
            self.bos_idx = (tokens == BOS_ID).nonzero(as_tuple=True)[0].to(torch.int64).cpu().numpy()
        self.i = 0
        self.world_size = world_size
        self.batch_iter = 0

    def _load(self):
        self.bos_idx_async = (self.tokens == BOS_ID).nonzero(as_tuple=True)[0].to(torch.int64).cpu().numpy()
        self.ready.set()

    def start(self):
        self.ready.clear()
        self.thread = threading.Thread(target=self._load)
        self.thread.start()

    def get(self):
        if self.thread:
            self.ready.wait()
            self.thread.join()
        self.bos_idx = self.bos_idx_async

    def next_batch(self, num_tokens_local: int, max_seq_len: int):
        # if quickload was used, repoint to the full dataset after 5 batches
        if self.quickload and self.batch_iter==5:
            self.get()
        n = len(self.bos_idx)
        starts = [[] for _ in range(self.world_size)]
        ends = [[] for _ in range(self.world_size)]

        idx = self.i
        for r in range(self.world_size):
            cur_len = 0
            while cur_len <= num_tokens_local:
                if idx >= n:
                    raise StopIteration(f"Insufficient BOS ahead; hit tail of shard.")
                cur = self.bos_idx[idx]
                starts[r].append(cur)
                end = min(self.bos_idx[idx + 1] if idx + 1 < n else self.size,
                          cur + max_seq_len,
                          cur + num_tokens_local - cur_len + 1)
                ends[r].append(end)
                cur_len += end - cur
                idx += 1

            assert cur_len == num_tokens_local + 1
        self.i = idx
        self.batch_iter+=1
        return starts, ends

class DataPreloader:
    # Helper for asynchronously loading next shard and indexing bos tokens
    def __init__(self, file_iter, world_size: int = 1):
        self.file_iter = file_iter
        self.world_size = world_size
        self.thread = None
        self.data = None
        self.ready = threading.Event()

    def _load(self):
        tokens = _load_data_shard(next(self.file_iter))
        self.data = (tokens, BOSFinder(tokens, self.world_size))
        self.ready.set()

    def start(self):
        self.ready.clear()
        self.thread = threading.Thread(target=self._load)
        self.thread.start()

    def get(self):
        if self.thread:
            self.ready.wait()
            self.thread.join()
        return self.data

def distributed_data_generator(filename_pattern: str, num_tokens: int, max_seq_len: int, grad_accum_steps: int = 1, align_to_bos: bool = True):
    # align_to_bos: each sequence begins with Beginning of Sequence token, sequences truncated to max_seq_len
    rank = dist.get_rank() if dist.is_initialized() else 0
    world_size = dist.get_world_size() if dist.is_initialized() else 1
    assert num_tokens % (world_size * grad_accum_steps) == 0, "Batch size must be divisible by world size"
    num_tokens = num_tokens // grad_accum_steps

    files = [Path(file) for file in sorted(glob.glob(filename_pattern))]
    if not files:
        raise FileNotFoundError(f"No files found for pattern: {filename_pattern}")

    file_iter = iter(files)  # Use itertools.cycle(files) for multi-epoch training
    tokens = _load_data_shard(next(file_iter))
    if align_to_bos:
        finder = BOSFinder(tokens, world_size=world_size, quickload=True)
        preloader = DataPreloader(file_iter, world_size)
        preloader.start()
    else:
        pos = 0  # for unaligned case

    while True:
        num_tokens_local = num_tokens // world_size
        max_num_docs = next_multiple_of_n(num_tokens_local // 300, n=128)  # median doc length is ~400

        if align_to_bos:
            try:
                seq_starts, seq_ends = finder.next_batch(num_tokens_local, max_seq_len)
                start_idxs, end_idxs = torch.tensor(seq_starts[rank]), torch.tensor(seq_ends[rank])
            except StopIteration:
                # This shard is exhausted, load the next one in the next loop iteration.
                tokens, finder = preloader.get()
                preloader.start()
                continue

            buf = torch.cat([tokens[i:j] for i, j in zip(start_idxs, end_idxs)])
            _inputs = buf[:-1]
            _targets = buf[1:]
            end_idxs[-1] -= 1  # last document was too long to account for _targets offset
            cum_lengths = (end_idxs - start_idxs).cumsum(0)

        else:
            if pos + num_tokens + 1 >= len(tokens):  # should not occur for val data
                tokens, pos = _load_data_shard(next(file_iter)), 0

            pos_local = pos + rank * num_tokens_local
            buf = tokens[pos_local: pos_local + num_tokens_local + 1]
            _inputs = buf[:-1].view(num_tokens_local, )
            _targets = buf[1:].view(num_tokens_local, )

            cum_lengths = torch.nonzero(_inputs == BOS_ID)[:, 0]
            pos += num_tokens


        _cum_lengths = torch.full((max_num_docs,), num_tokens_local)
        _cum_lengths[0] = 0
        _cum_lengths[1:len(cum_lengths) + 1] = cum_lengths

        # Cast to int32 on CPU before transfer to avoid dtype conversion during .to()
        _inputs = _inputs.to(dtype=torch.int32)
        _targets = _targets.to(dtype=torch.int64)
        _cum_lengths = _cum_lengths.to(dtype=torch.int32)

        new_params = yield (
            _inputs.to(device="cuda", non_blocking=True),
            _targets.to(device="cuda", non_blocking=True),
            _cum_lengths.to(device="cuda", non_blocking=True)
        )

        if new_params is not None:
            # makes it possible for generator to receive new (num_tokens, max_seq_len, grad_accum_steps) via .send()
            new_num_tokens, new_max_seq_len, new_grad_accum_steps = new_params
            assert new_num_tokens % (world_size * new_grad_accum_steps) == 0, "Num tokens must be divisible by world size"
            num_tokens = new_num_tokens // new_grad_accum_steps
            max_seq_len = new_max_seq_len

# -----------------------------------------------------------------------------
# Training Management
 
def get_bs(step: int):
    if step >= args.num_scheduled_iterations:
        return args.train_bs_extension
    x = step / args.num_scheduled_iterations
    bs_idx = int(len(args.train_bs_schedule) * x)
    return args.train_bs_schedule[bs_idx]

def get_ws(step: int):
    # set short window size to half of long window size
    # Higher ws on "extension" steps
    if step >= args.num_scheduled_iterations:
        return args.ws_final // 2, args.ws_final
    x = step / args.num_scheduled_iterations
    assert 0 <= x < 1
    ws_idx = int(len(args.ws_schedule) * x)
    return args.ws_schedule[ws_idx] // 2, args.ws_schedule[ws_idx]

# learning rate schedule: tied to batch size schedule, with cooldown at the end.
def get_lr(step: int):
    if step > args.num_scheduled_iterations:
        return 0.1
    lr_max = 1.0
    x = step / args.num_scheduled_iterations
    if x > 1/3:
       lr_max = 1.52  # (16/8)**0.6
    if x > 2/3:
        lr_max = 1.73  # (24/8)**0.5
    if x >= 1 - args.cooldown_frac:
        w = (1 - x) / args.cooldown_frac
        lr = lr_max * w + (1 - w) * 0.1
        return lr
    return lr_max

def get_muon_momentum(step: int, muon_warmup_steps=300, muon_cooldown_steps=50, momentum_min=0.85, momentum_max=0.95):
    # warmup phase: linearly increase momentum from min to max
    # cooldown phase: linearly decrease momentum from max to min
    momentum_cd_start = args.num_iterations - muon_cooldown_steps
    if step < muon_warmup_steps:
        frac = step / muon_warmup_steps
        momentum = momentum_min + frac * (momentum_max - momentum_min)
    elif step > momentum_cd_start:
        frac = (step - momentum_cd_start) / muon_cooldown_steps
        momentum = momentum_max - frac * (momentum_max - momentum_min)
    else:
        momentum = momentum_max
    return momentum

class TrainingManager():
    """
    Manages three optimizers for Adam embed/lm_head, Adam scalars, and Muon weight matrices.
    Notable Features:
        1. Scalars are given higher momentum terms to smooth learning @ChrisJMcCormick
        2. Scalar weights are temporarily frozen during batch size or window size updates @ChrisJMcCormick
        3. Adam optimizers are only stepped on odd steps @classiclarryd
        4. Adam optimizers have hooks to start gradient communication during backwards pass @akash5474
        5. Muon has a linear momentum warmup and cooldown schedule
        6. Learning rates follow a linear decay schedule
        7. Embed/lm_head weights and optimizer state splits at 2/3 of training @classiclarryd

    Manages model architecture, data, and target that changes during training
    Notable Features:
        1. Multi Token Prediction schedule of [1, 0.5, 0.25->0] -> [1, 0.5->0] -> [1] @varunneal
        2. Sliding Attention window schedule of [1,3] -> [3,7] -> [5,11] -> [6,13]
        3. YaRN updates to RoPE on window changes
        4. Split embed and lm head at 2/3 of training
        5. Batch size schedule of 8 -> 16 -> 24
        6. Post training extension of long windows from 13 to 20
    """
    def __init__(self, model):
        self.mtp_weights_schedule = self._build_mtp_schedule()
        self.model = model
        adam_betas = {
            'lm_head': [0.5, 0.95],
            'smear_gate': [0.9, 0.99],
            'attn_gate_bank': [0.9, 0.99],
            've_gate_bank': [0.9, 0.99],
            'skip_gate': [0.9, 0.99],
            'x0_lambdas': [0.65, 0.95],
            'scalars': [0.9, 0.99],
            'embed': [0.5, 0.95],
            'value_embed': [0.75, 0.95]
        }
        adam_labels = list(adam_betas.keys())
        adam_beta_values = list(adam_betas.values())
        muon_labels = ['attn', 'mlp']
        adam_params = [p for p in model.parameters() if getattr(p, 'label', None) in adam_labels]
        muon_params = [p for p in model.parameters() if getattr(p, 'label', None) in muon_labels]
        assert set(getattr(p, 'label', None) for p in model.parameters()) == set(adam_labels + muon_labels), "All params must have label"

        self.adam_opt = DistAdam(adam_params, adam_labels, adam_beta_values, lr=0.008, eps=1e-10, weight_decay=0.005)
        self.muon_opt = NorMuon(muon_params, lr=0.023, momentum=0.95, beta2=0.95, weight_decay=1.2)
        self.optimizers = [self.adam_opt, self.muon_opt]

        # split after odd number step
        self.split_step = math.ceil(args.split_embed_frac * args.num_scheduled_iterations) | 1

        # set defaults
        for opt in self.optimizers:
            opt.odd_step_only = False 
            opt.should_sync = True
            for group in opt.param_groups:
                group["initial_lr"] = group["lr"]

        # on even steps, only step Muon params
        self.adam_opt.odd_step_only = True

        self.reset()

    def _build_mtp_schedule(self):
        # Precompute MTP weights for all steps to avoid tensor allocation during training
        # Schedule: [1, 0.5, 0.25->0] -> [1, 0.5->0] -> [1]
        mtp_weights_schedule = []
        for s in range(args.num_iterations + 1):
            x = s / args.num_scheduled_iterations
            if x < 1/3:
                w = [1.0, 0.5, 0.25 * (1 - 3*x)]
            elif x < 2/3:
                w = [1.0, 0.5 * (1 - (3*x - 1))]
            else:
                w = [1.0]
            mtp_weights_schedule.append(torch.tensor(w, device=device))
        return mtp_weights_schedule

    def apply_final_ws_ext(self):
        self.ws_long = args.ws_validate_post_yarn_ext

    def get_forward_args(self):
        return ForwardScheduleConfig(
            mtp_weights = self.mtp_weights,
            ws_short = self.ws_short,
            ws_long = self.ws_long
        )
    
    def _is_active_step(self, opt, step: int):
        return (opt.odd_step_only and step%2==1) or not opt.odd_step_only

    def get_transition_steps(self):
        transition_steps = []
        ws_short, ws_long = get_ws(0)
        for step in range(1, args.num_iterations):
            ws_short, new_ws_long = get_ws(step)
            if new_ws_long != ws_long:
                transition_steps.append(step)
                ws_long = new_ws_long
        return transition_steps

    def advance_schedule(self, step: int):
        self.ws_short, new_ws_long = get_ws(step)
        if new_ws_long != self.ws_long:
            self.model.yarn.apply(self.ws_long, new_ws_long)
            self.model.yarn_paired_head.apply(self.ws_long, new_ws_long)

        new_batch_size = get_bs(step)
        if new_batch_size != self.batch_size:
            self.train_loader_send_args = (new_batch_size, args.train_max_seq_len, grad_accum_steps)
        else:
            self.train_loader_send_args = None

        self.ws_long = new_ws_long
        self.mtp_weights = self.mtp_weights_schedule[step]
    
    def step_optimizers(self, step: int):                
        step_lr = get_lr(step)
        muon_momentum = get_muon_momentum(step)
        for group in self.muon_opt.param_groups:
            group["momentum"] = muon_momentum

        for opt in self.optimizers:
            for group in opt.param_groups:
                group["lr"] = group["initial_lr"] * step_lr
                
        if self._is_active_step(self.adam_opt, step):
            # adam will interleave calls to muon step
            self.adam_opt.step(self.muon_opt)
            self.model.zero_grad(set_to_none=True)
            self.adam_opt.should_sync = False
        else:
            self.muon_opt.step()
            self.muon_opt.zero_grad(set_to_none=True)
            
        if step == self.split_step:
            self.adam_opt.copy_lm_to_embed()
            self.model.split_embed = True
    
    def activate_hooks(self, step: int):
        for opt in self.optimizers:
            if self._is_active_step(opt, step):
                opt.should_sync = True

    def reset(self, state=None):
        if state is not None:
            for opt, opt_state in zip(self.optimizers, state):
                opt.should_sync = False
                opt.load_state_dict(opt_state)

        # muon momentum buffers not in state dict
        self.muon_opt.reset()
        self.model.split_embed = False

        self.ws_short, self.ws_long = get_ws(0)
        self.batch_size = get_bs(0)
        self.model.yarn.reset()
        self.model.yarn_paired_head.reset()

    def get_state(self):
        return [copy.deepcopy(opt.state_dict()) for opt in self.optimizers]

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files: str = "data/fineweb10B/fineweb_train_*.bin" # input .bin to train on
    val_files: str = "data/fineweb10B/fineweb_val_*.bin" # input .bin to eval validation loss on
    val_tokens: int = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    # batch sizes
    train_bs_schedule: tuple = (8 * 2048 * 8, 16 * 2048 * 8, 24 * 2048 * 8)
    train_bs_extension: int = 24 * 2048 * 8
    train_max_seq_len: int = 128 * 16
    val_batch_size: int = 4 * 64 * 1024 * 8
    # optimization
    num_scheduled_iterations: int = 1735  # number of steps to complete lr and ws schedule
    num_extension_iterations: int = 40  # number of steps to continue training at final lr and ws
    num_iterations: int = num_scheduled_iterations + num_extension_iterations
    cooldown_frac: float = 0.50  # fraction of num_scheduled_iterations spent cooling down the learning rate
    split_embed_frac: float = 2/3  # fraction of training when embeddings split from lm_head
    # evaluation and logging
    run_id: str = f"{uuid.uuid4()}"
    val_loss_every: int = 250  # every how many steps to evaluate val loss? 0 for only at the end
    save_checkpoint: bool = False
    # attention masking
    block_size: int = 128
    ws_schedule: tuple = (3, 7, 11)
    ws_final: int = 13 # increase final validation ws, used for YaRN extension and short window size @classiclarryd
    ws_validate_post_yarn_ext: int = 20 # extend long windows out even further after applying YaRN

args = Hyperparameters()

data_path = os.environ.get("DATA_PATH", ".")
args.train_files = os.path.join(data_path, args.train_files)
args.val_files = os.path.join(data_path, args.val_files)

# torchrun sets these env variables
rank = int(os.environ["RANK"])
world_size = int(os.environ["WORLD_SIZE"])
assert 8 % world_size == 0, "world_size must be a divisor of 8"
grad_accum_steps = 8 // world_size
assert torch.cuda.is_available()
device = torch.device("cuda", int(os.environ["LOCAL_RANK"]))
torch.cuda.set_device(device)
dist.init_process_group(backend="nccl", device_id=device)
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = args.run_id
    os.makedirs("logs", exist_ok=True)
    logfile = f"logs/{run_id}.txt"
    print(logfile)
def print0(s, console=False):
    if master_process:
        with open(logfile, "a") as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0("="*100)
# log information about the hardware/software environment this is running on
print0(f"Running Python {sys.version}")
print0(f"Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}")
print0(f"Running Triton version {triton.__version__}")

def nvidia_smi():
    import subprocess  # avoid top level import
    return subprocess.run(["nvidia-smi"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout
print0(nvidia_smi())
print0("="*100)

model: nn.Module = GPT(
    vocab_size=50257,
    num_layers=11,
    num_heads=6,
    head_dim=128,
    model_dim=768,
    max_seq_len=args.val_batch_size // (grad_accum_steps * world_size),
    use_malbo=os.environ.get('use_malbo', 'True') == 'True',
).cuda()
for m in model.modules():
    if isinstance(m, (nn.Embedding, nn.Linear)):
        m.weight.data = m.weight.data.bfloat16()
model.attn_gate_bank.data = model.attn_gate_bank.data.bfloat16()
model.ve_gate_bank.data = model.ve_gate_bank.data.bfloat16()
for param in model.parameters():
    dist.broadcast(param.detach(), 0)

model: nn.Module = torch.compile(model, dynamic=False, fullgraph=False)
training_manager = TrainingManager(model)

########################################
#            Warmup kernels            #
########################################
print0("Compiling model and warming up kernels (~7 minutes on first execution)", console=True)
# Warmup the training kernels, then re-initialize the state so we aren't cheating
initial_state = dict(model=copy.deepcopy(model.state_dict()),
                     optimizers=training_manager.get_state()) # save the initial state
train_loader = distributed_data_generator(args.train_files, args.train_bs_schedule[0], args.train_max_seq_len, grad_accum_steps=grad_accum_steps)
val_loader = distributed_data_generator(args.val_files, args.val_batch_size, -1, grad_accum_steps=grad_accum_steps, align_to_bos=False)

transition_steps = training_manager.get_transition_steps()
# first few steps plus transitions
warmup_steps = sorted({0, 1, 2} | set(s + offset for s in transition_steps for offset in [-1, 0, 1] if s + offset >= 0)) 
print0(f"Sampling steps {warmup_steps} for warmup", console=True)
for step in warmup_steps:
    training_manager.advance_schedule(step)
    model.eval()
    with torch.no_grad():
        inputs, targets, cum_seqlens = next(val_loader)
        model(inputs, targets, cum_seqlens, training_manager.get_forward_args())
    model.train()
    for idx in range(grad_accum_steps):
        # enable gradient sync for the DistAdam optimizers on the last iteration before we step them
        if idx == grad_accum_steps - 1:
            training_manager.activate_hooks(step)
        send_args = training_manager.train_loader_send_args
        inputs, targets, cum_seqlens = train_loader.send(send_args)
        (model(inputs, targets, cum_seqlens, training_manager.get_forward_args())[1] / grad_accum_steps).backward()
    training_manager.step_optimizers(step)
    break
print0("Resetting Model", console=True)
model.zero_grad(set_to_none=True)
model.load_state_dict(initial_state["model"])
training_manager.reset(initial_state["optimizers"])
del val_loader, train_loader, initial_state
model.train()

########################################
#        Training and validation       #
########################################
train_loader = distributed_data_generator(args.train_files, args.train_bs_schedule[0], args.train_max_seq_len, grad_accum_steps=grad_accum_steps)

gc.collect()

training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)
    training_manager.advance_schedule(step)
    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        if last_step:
            training_manager.apply_final_ws_ext()
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        model.eval()
        assert args.val_tokens % args.val_batch_size == 0
        val_steps = grad_accum_steps * args.val_tokens // args.val_batch_size
        val_loader = distributed_data_generator(args.val_files, args.val_batch_size, -1, grad_accum_steps=grad_accum_steps, align_to_bos=False)
        val_loss, val_malbo_loss = 0, 0
        with torch.no_grad():
            for _ in range(val_steps):
                inputs, targets, cum_seqlens = next(val_loader)
                this_val_loss, this_val_malbo_loss = model(inputs, targets, cum_seqlens, training_manager.get_forward_args())
                val_loss += this_val_loss
                val_malbo_loss += this_val_malbo_loss
        val_loss /= val_steps
        val_malbo_loss /= val_steps
        del val_loader
        dist.reduce(val_loss, 0, op=dist.ReduceOp.AVG)
        dist.reduce(val_malbo_loss, 0, op=dist.ReduceOp.AVG)
        print0(f"step:{step}/{train_steps} val_loss:{val_loss:.4f} val_malbo_loss:{val_malbo_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/max(step, 1):.2f}ms", console=True)
        model.train()
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f"logs/{run_id}", exist_ok=True)
            torch.save(log, f"logs/{run_id}/state_step{step:06d}.pt")
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    for idx in range(grad_accum_steps):
        # enable gradient sync for the DistAdam optimizers on the last iteration before we step them
        if idx == grad_accum_steps - 1:
            training_manager.activate_hooks(step)
        send_args = training_manager.train_loader_send_args
        inputs, targets, cum_seqlens = train_loader.send(send_args)
        (model(inputs, targets, cum_seqlens, training_manager.get_forward_args())[1] / grad_accum_steps).backward()
    training_manager.step_optimizers(step)

    # logging
    approx_training_time_ms = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f"step:{step+1}/{train_steps} train_time:{approx_training_time_ms:.0f}ms step_avg:{approx_training_time_ms/(step + 1):.2f}ms", console=True)

print0(f"peak memory allocated: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB "
       f"reserved: {torch.cuda.max_memory_reserved() // 1024 // 1024} MiB", console=True)
dist.destroy_process_group()

====================================================================================================
Running Python 3.10.19 (main, Oct 21 2025, 16:43:05) [GCC 11.2.0]
Running PyTorch 2.10.0.dev20251210+cu126 compiled for CUDA 12.6
Running Triton version 3.6.0
Thu Jan 15 04:25:44 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 PCIe               On  |   00000000:D6:00.0 Off |                    0 |
| N/A   24C    P0             75W /  310W |    1103MiB /  81559MiB |      5%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A           26214      C   .../envs/speedrun/bin/python3.10       1094MiB |
+-----------------------------------------------------------------------------------------+

====================================================================================================
Compiling model and warming up kernels (~7 minutes on first execution)
Sampling steps [0, 1, 2, 578, 579, 580, 1156, 1157, 1158, 1734, 1735, 1736] for warmup
Resetting Model
step:0/1775 val_loss:10.8297 val_malbo_loss:10.8297 train_time:0ms step_avg:0.03ms
step:1/1775 train_time:987ms step_avg:987.42ms
step:2/1775 train_time:2330ms step_avg:1165.16ms
step:3/1775 train_time:2818ms step_avg:939.27ms
step:4/1775 train_time:3300ms step_avg:824.97ms
step:5/1775 train_time:3779ms step_avg:755.73ms
step:6/1775 train_time:4293ms step_avg:715.43ms
step:7/1775 train_time:4775ms step_avg:682.12ms
step:8/1775 train_time:5337ms step_avg:667.18ms
step:9/1775 train_time:5880ms step_avg:653.34ms
step:10/1775 train_time:6408ms step_avg:640.76ms
step:11/1775 train_time:6959ms step_avg:632.67ms
step:12/1775 train_time:7490ms step_avg:624.15ms
step:13/1775 train_time:8027ms step_avg:617.45ms
step:14/1775 train_time:8543ms step_avg:610.22ms
step:15/1775 train_time:9052ms step_avg:603.49ms
step:16/1775 train_time:9578ms step_avg:598.63ms
step:17/1775 train_time:10065ms step_avg:592.04ms
step:18/1775 train_time:10546ms step_avg:585.88ms
step:19/1775 train_time:11028ms step_avg:580.43ms
step:20/1775 train_time:11519ms step_avg:575.93ms
step:21/1775 train_time:11992ms step_avg:571.06ms
step:22/1775 train_time:12479ms step_avg:567.21ms
step:23/1775 train_time:12963ms step_avg:563.62ms
step:24/1775 train_time:13453ms step_avg:560.52ms
step:25/1775 train_time:13956ms step_avg:558.24ms
step:26/1775 train_time:14451ms step_avg:555.81ms
step:27/1775 train_time:14949ms step_avg:553.65ms
step:28/1775 train_time:15436ms step_avg:551.29ms
step:29/1775 train_time:15906ms step_avg:548.49ms
step:30/1775 train_time:16391ms step_avg:546.36ms
step:31/1775 train_time:16873ms step_avg:544.30ms
step:32/1775 train_time:17364ms step_avg:542.61ms
step:33/1775 train_time:17836ms step_avg:540.47ms
step:34/1775 train_time:18319ms step_avg:538.78ms
step:35/1775 train_time:18786ms step_avg:536.75ms
step:36/1775 train_time:19264ms step_avg:535.10ms
step:37/1775 train_time:19751ms step_avg:533.82ms
step:38/1775 train_time:20251ms step_avg:532.92ms
step:39/1775 train_time:20738ms step_avg:531.75ms
step:40/1775 train_time:21231ms step_avg:530.77ms
step:41/1775 train_time:21718ms step_avg:529.70ms
step:42/1775 train_time:22197ms step_avg:528.51ms
step:43/1775 train_time:22666ms step_avg:527.11ms
step:44/1775 train_time:23142ms step_avg:525.95ms
step:45/1775 train_time:23623ms step_avg:524.95ms
step:46/1775 train_time:24104ms step_avg:524.01ms
step:47/1775 train_time:24593ms step_avg:523.25ms
step:48/1775 train_time:25076ms step_avg:522.43ms
step:49/1775 train_time:25554ms step_avg:521.51ms
step:50/1775 train_time:26033ms step_avg:520.66ms
step:51/1775 train_time:26511ms step_avg:519.83ms
step:52/1775 train_time:26997ms step_avg:519.16ms
step:53/1775 train_time:27461ms step_avg:518.13ms
step:54/1775 train_time:27939ms step_avg:517.39ms
step:55/1775 train_time:28405ms step_avg:516.45ms
step:56/1775 train_time:28879ms step_avg:515.69ms
step:57/1775 train_time:29371ms step_avg:515.27ms
step:58/1775 train_time:29892ms step_avg:515.39ms
step:59/1775 train_time:30418ms step_avg:515.56ms
step:60/1775 train_time:30922ms step_avg:515.36ms
step:61/1775 train_time:31431ms step_avg:515.25ms
step:62/1775 train_time:31969ms step_avg:515.62ms
step:63/1775 train_time:32453ms step_avg:515.12ms
step:64/1775 train_time:32940ms step_avg:514.69ms
step:65/1775 train_time:33421ms step_avg:514.17ms
step:66/1775 train_time:33902ms step_avg:513.67ms
step:67/1775 train_time:34377ms step_avg:513.08ms
step:68/1775 train_time:34869ms step_avg:512.77ms
step:69/1775 train_time:35346ms step_avg:512.25ms
step:70/1775 train_time:35840ms step_avg:511.99ms
step:71/1775 train_time:36318ms step_avg:511.53ms
step:72/1775 train_time:36802ms step_avg:511.14ms
step:73/1775 train_time:37281ms step_avg:510.69ms
step:74/1775 train_time:37775ms step_avg:510.47ms
step:75/1775 train_time:38254ms step_avg:510.05ms
step:76/1775 train_time:38737ms step_avg:509.70ms
step:77/1775 train_time:39211ms step_avg:509.24ms
step:78/1775 train_time:39696ms step_avg:508.92ms
step:79/1775 train_time:40192ms step_avg:508.76ms
step:80/1775 train_time:40667ms step_avg:508.33ms
step:81/1775 train_time:41166ms step_avg:508.22ms
step:82/1775 train_time:41665ms step_avg:508.11ms
step:83/1775 train_time:42197ms step_avg:508.40ms
step:84/1775 train_time:42737ms step_avg:508.77ms
step:85/1775 train_time:43292ms step_avg:509.32ms
step:86/1775 train_time:43814ms step_avg:509.46ms
step:87/1775 train_time:44339ms step_avg:509.65ms
step:88/1775 train_time:44869ms step_avg:509.87ms
step:89/1775 train_time:45415ms step_avg:510.28ms
step:90/1775 train_time:45946ms step_avg:510.51ms
step:91/1775 train_time:46446ms step_avg:510.40ms
step:92/1775 train_time:46963ms step_avg:510.46ms
step:93/1775 train_time:47473ms step_avg:510.46ms
step:94/1775 train_time:47993ms step_avg:510.56ms
step:95/1775 train_time:48502ms step_avg:510.54ms
step:96/1775 train_time:48990ms step_avg:510.32ms
step:97/1775 train_time:49498ms step_avg:510.29ms
step:98/1775 train_time:50011ms step_avg:510.32ms
step:99/1775 train_time:50503ms step_avg:510.14ms
step:100/1775 train_time:50994ms step_avg:509.94ms
step:101/1775 train_time:51473ms step_avg:509.64ms
step:102/1775 train_time:51956ms step_avg:509.38ms
step:103/1775 train_time:52430ms step_avg:509.03ms
step:104/1775 train_time:52930ms step_avg:508.95ms
step:105/1775 train_time:53402ms step_avg:508.59ms
step:106/1775 train_time:53894ms step_avg:508.43ms
step:107/1775 train_time:54356ms step_avg:508.00ms
step:108/1775 train_time:54853ms step_avg:507.90ms
step:109/1775 train_time:55350ms step_avg:507.80ms
step:110/1775 train_time:55841ms step_avg:507.64ms
step:111/1775 train_time:56321ms step_avg:507.39ms
step:112/1775 train_time:56822ms step_avg:507.34ms
step:113/1775 train_time:57311ms step_avg:507.18ms
step:114/1775 train_time:57788ms step_avg:506.91ms
step:115/1775 train_time:58273ms step_avg:506.72ms
step:116/1775 train_time:58749ms step_avg:506.46ms
step:117/1775 train_time:59231ms step_avg:506.25ms
step:118/1775 train_time:59732ms step_avg:506.20ms
step:119/1775 train_time:60219ms step_avg:506.05ms
step:120/1775 train_time:60705ms step_avg:505.88ms
step:121/1775 train_time:61210ms step_avg:505.87ms
step:122/1775 train_time:61705ms step_avg:505.78ms
step:123/1775 train_time:62201ms step_avg:505.70ms
step:124/1775 train_time:62682ms step_avg:505.50ms
step:125/1775 train_time:63176ms step_avg:505.41ms
step:126/1775 train_time:63661ms step_avg:505.25ms
step:127/1775 train_time:64139ms step_avg:505.03ms
step:128/1775 train_time:64630ms step_avg:504.93ms
step:129/1775 train_time:65122ms step_avg:504.82ms
step:130/1775 train_time:65599ms step_avg:504.61ms
step:131/1775 train_time:66084ms step_avg:504.46ms
step:132/1775 train_time:66561ms step_avg:504.25ms
step:133/1775 train_time:67049ms step_avg:504.13ms
step:134/1775 train_time:67523ms step_avg:503.91ms
step:135/1775 train_time:68005ms step_avg:503.74ms
step:136/1775 train_time:68494ms step_avg:503.63ms
step:137/1775 train_time:68966ms step_avg:503.40ms
step:138/1775 train_time:69445ms step_avg:503.22ms
step:139/1775 train_time:69920ms step_avg:503.02ms
step:140/1775 train_time:70394ms step_avg:502.81ms
step:141/1775 train_time:70884ms step_avg:502.72ms
step:142/1775 train_time:71353ms step_avg:502.49ms
step:143/1775 train_time:71824ms step_avg:502.27ms
step:144/1775 train_time:72323ms step_avg:502.24ms
step:145/1775 train_time:72807ms step_avg:502.12ms
step:146/1775 train_time:73301ms step_avg:502.06ms
step:147/1775 train_time:73788ms step_avg:501.96ms
step:148/1775 train_time:74291ms step_avg:501.96ms
step:149/1775 train_time:74765ms step_avg:501.78ms
step:150/1775 train_time:75257ms step_avg:501.71ms
step:151/1775 train_time:75730ms step_avg:501.52ms
step:152/1775 train_time:76207ms step_avg:501.36ms
step:153/1775 train_time:76682ms step_avg:501.19ms
step:154/1775 train_time:77210ms step_avg:501.37ms
step:155/1775 train_time:77629ms step_avg:500.84ms
step:156/1775 train_time:78109ms step_avg:500.70ms
step:157/1775 train_time:78579ms step_avg:500.50ms
step:158/1775 train_time:79053ms step_avg:500.34ms
step:159/1775 train_time:79531ms step_avg:500.20ms
step:160/1775 train_time:80009ms step_avg:500.06ms
step:161/1775 train_time:80516ms step_avg:500.10ms
step:162/1775 train_time:81031ms step_avg:500.19ms
step:163/1775 train_time:81533ms step_avg:500.20ms
step:164/1775 train_time:82044ms step_avg:500.27ms
step:165/1775 train_time:82545ms step_avg:500.27ms
step:166/1775 train_time:83117ms step_avg:500.70ms
step:167/1775 train_time:83661ms step_avg:500.97ms
step:168/1775 train_time:84170ms step_avg:501.01ms
step:169/1775 train_time:84707ms step_avg:501.22ms
step:170/1775 train_time:85296ms step_avg:501.74ms
step:171/1775 train_time:85835ms step_avg:501.96ms
step:172/1775 train_time:86402ms step_avg:502.34ms
step:173/1775 train_time:86921ms step_avg:502.43ms
step:174/1775 train_time:87442ms step_avg:502.54ms
step:175/1775 train_time:87963ms step_avg:502.64ms
step:176/1775 train_time:88475ms step_avg:502.70ms
step:177/1775 train_time:88966ms step_avg:502.63ms
step:178/1775 train_time:89479ms step_avg:502.69ms
step:179/1775 train_time:89981ms step_avg:502.69ms
step:180/1775 train_time:90476ms step_avg:502.65ms
step:181/1775 train_time:90939ms step_avg:502.43ms
step:182/1775 train_time:91416ms step_avg:502.29ms
step:183/1775 train_time:91898ms step_avg:502.18ms
step:184/1775 train_time:92396ms step_avg:502.15ms
step:185/1775 train_time:92902ms step_avg:502.17ms
step:186/1775 train_time:93429ms step_avg:502.31ms
step:187/1775 train_time:93948ms step_avg:502.40ms
step:188/1775 train_time:94462ms step_avg:502.46ms
step:189/1775 train_time:95001ms step_avg:502.65ms
step:190/1775 train_time:95507ms step_avg:502.67ms
step:191/1775 train_time:95985ms step_avg:502.54ms
step:192/1775 train_time:96474ms step_avg:502.47ms
step:193/1775 train_time:96963ms step_avg:502.40ms
step:194/1775 train_time:97464ms step_avg:502.39ms
step:195/1775 train_time:97994ms step_avg:502.53ms
step:196/1775 train_time:98465ms step_avg:502.37ms
step:197/1775 train_time:98936ms step_avg:502.21ms
step:198/1775 train_time:99438ms step_avg:502.21ms
step:199/1775 train_time:99909ms step_avg:502.06ms
step:200/1775 train_time:100402ms step_avg:502.01ms
step:201/1775 train_time:100888ms step_avg:501.93ms
step:202/1775 train_time:101377ms step_avg:501.87ms
step:203/1775 train_time:101861ms step_avg:501.78ms
step:204/1775 train_time:102365ms step_avg:501.79ms
step:205/1775 train_time:102832ms step_avg:501.62ms
step:206/1775 train_time:103322ms step_avg:501.56ms
step:207/1775 train_time:103807ms step_avg:501.48ms
step:208/1775 train_time:104286ms step_avg:501.37ms
step:209/1775 train_time:104764ms step_avg:501.27ms
step:210/1775 train_time:105241ms step_avg:501.15ms
step:211/1775 train_time:105715ms step_avg:501.02ms
step:212/1775 train_time:106205ms step_avg:500.97ms
step:213/1775 train_time:106676ms step_avg:500.83ms
step:214/1775 train_time:107161ms step_avg:500.75ms
step:215/1775 train_time:107662ms step_avg:500.76ms
step:216/1775 train_time:108163ms step_avg:500.75ms
step:217/1775 train_time:108644ms step_avg:500.66ms
step:218/1775 train_time:109137ms step_avg:500.63ms
step:219/1775 train_time:109652ms step_avg:500.70ms
step:220/1775 train_time:110161ms step_avg:500.73ms
step:221/1775 train_time:110690ms step_avg:500.86ms
step:222/1775 train_time:111235ms step_avg:501.06ms
step:223/1775 train_time:111770ms step_avg:501.21ms
step:224/1775 train_time:112300ms step_avg:501.34ms
step:225/1775 train_time:112789ms step_avg:501.28ms
step:226/1775 train_time:113269ms step_avg:501.19ms
step:227/1775 train_time:113788ms step_avg:501.27ms
step:228/1775 train_time:114320ms step_avg:501.40ms
step:229/1775 train_time:114815ms step_avg:501.38ms
step:230/1775 train_time:115309ms step_avg:501.34ms
step:231/1775 train_time:115779ms step_avg:501.21ms
step:232/1775 train_time:116250ms step_avg:501.08ms
step:233/1775 train_time:116732ms step_avg:501.00ms
step:234/1775 train_time:117215ms step_avg:500.92ms
step:235/1775 train_time:117692ms step_avg:500.82ms
step:236/1775 train_time:118164ms step_avg:500.70ms
step:237/1775 train_time:118654ms step_avg:500.65ms
step:238/1775 train_time:119138ms step_avg:500.58ms
step:239/1775 train_time:119643ms step_avg:500.60ms
step:240/1775 train_time:120122ms step_avg:500.51ms
step:241/1775 train_time:120628ms step_avg:500.53ms
step:242/1775 train_time:121123ms step_avg:500.51ms
step:243/1775 train_time:121627ms step_avg:500.52ms
step:244/1775 train_time:122143ms step_avg:500.59ms
step:245/1775 train_time:122655ms step_avg:500.63ms
step:246/1775 train_time:123194ms step_avg:500.79ms
step:247/1775 train_time:123746ms step_avg:501.00ms
step:248/1775 train_time:124305ms step_avg:501.23ms
step:249/1775 train_time:124870ms step_avg:501.49ms
step:250/1775 train_time:125448ms step_avg:501.79ms
step:250/1775 val_loss:4.5944 val_malbo_loss:4.5630 train_time:125449ms step_avg:501.80ms
step:251/1775 train_time:125914ms step_avg:501.65ms
step:252/1775 train_time:126406ms step_avg:501.61ms
step:253/1775 train_time:126879ms step_avg:501.50ms
step:254/1775 train_time:127367ms step_avg:501.44ms
step:255/1775 train_time:127843ms step_avg:501.34ms
step:256/1775 train_time:128339ms step_avg:501.32ms
step:257/1775 train_time:128825ms step_avg:501.27ms
step:258/1775 train_time:129312ms step_avg:501.21ms
step:259/1775 train_time:129801ms step_avg:501.16ms
step:260/1775 train_time:130293ms step_avg:501.13ms
step:261/1775 train_time:130769ms step_avg:501.03ms
step:262/1775 train_time:131251ms step_avg:500.96ms
step:263/1775 train_time:131727ms step_avg:500.86ms
step:264/1775 train_time:132217ms step_avg:500.82ms
step:265/1775 train_time:132693ms step_avg:500.73ms
step:266/1775 train_time:133181ms step_avg:500.68ms
step:267/1775 train_time:133663ms step_avg:500.61ms
step:268/1775 train_time:134153ms step_avg:500.57ms
step:269/1775 train_time:134679ms step_avg:500.67ms
step:270/1775 train_time:135179ms step_avg:500.66ms
step:271/1775 train_time:135665ms step_avg:500.61ms
step:272/1775 train_time:136149ms step_avg:500.55ms
step:273/1775 train_time:136634ms step_avg:500.49ms
step:274/1775 train_time:137129ms step_avg:500.47ms
step:275/1775 train_time:137614ms step_avg:500.41ms
step:276/1775 train_time:138124ms step_avg:500.45ms
step:277/1775 train_time:138658ms step_avg:500.57ms
step:278/1775 train_time:139170ms step_avg:500.61ms
step:279/1775 train_time:139693ms step_avg:500.69ms
step:280/1775 train_time:140220ms step_avg:500.78ms
step:281/1775 train_time:140718ms step_avg:500.77ms
step:282/1775 train_time:141224ms step_avg:500.79ms
step:283/1775 train_time:141773ms step_avg:500.96ms
step:284/1775 train_time:142289ms step_avg:501.02ms
step:285/1775 train_time:142794ms step_avg:501.03ms
step:286/1775 train_time:143320ms step_avg:501.12ms
step:287/1775 train_time:143843ms step_avg:501.19ms
step:288/1775 train_time:144377ms step_avg:501.31ms
step:289/1775 train_time:144930ms step_avg:501.49ms
step:290/1775 train_time:145442ms step_avg:501.53ms
step:291/1775 train_time:145958ms step_avg:501.58ms
step:292/1775 train_time:146435ms step_avg:501.49ms
step:293/1775 train_time:146936ms step_avg:501.49ms
step:294/1775 train_time:147429ms step_avg:501.46ms
step:295/1775 train_time:147907ms step_avg:501.38ms
step:296/1775 train_time:148398ms step_avg:501.34ms
step:297/1775 train_time:148875ms step_avg:501.26ms
step:298/1775 train_time:149388ms step_avg:501.30ms
step:299/1775 train_time:149909ms step_avg:501.37ms
step:300/1775 train_time:150441ms step_avg:501.47ms
step:301/1775 train_time:150979ms step_avg:501.59ms
step:302/1775 train_time:151504ms step_avg:501.67ms
step:303/1775 train_time:152035ms step_avg:501.77ms
step:304/1775 train_time:152611ms step_avg:502.01ms
step:305/1775 train_time:153155ms step_avg:502.15ms
step:306/1775 train_time:153701ms step_avg:502.29ms
step:307/1775 train_time:154288ms step_avg:502.57ms
step:308/1775 train_time:154878ms step_avg:502.85ms
step:309/1775 train_time:155435ms step_avg:503.03ms
step:310/1775 train_time:155994ms step_avg:503.21ms
step:311/1775 train_time:156519ms step_avg:503.28ms
step:312/1775 train_time:157031ms step_avg:503.31ms
step:313/1775 train_time:157545ms step_avg:503.34ms
step:314/1775 train_time:158080ms step_avg:503.44ms
step:315/1775 train_time:158599ms step_avg:503.49ms
step:316/1775 train_time:159119ms step_avg:503.54ms
step:317/1775 train_time:159636ms step_avg:503.58ms
step:318/1775 train_time:160145ms step_avg:503.60ms
step:319/1775 train_time:160637ms step_avg:503.56ms
step:320/1775 train_time:161135ms step_avg:503.55ms
step:321/1775 train_time:161600ms step_avg:503.43ms
step:322/1775 train_time:162099ms step_avg:503.41ms
step:323/1775 train_time:162589ms step_avg:503.37ms
step:324/1775 train_time:163069ms step_avg:503.30ms
step:325/1775 train_time:163551ms step_avg:503.23ms
step:326/1775 train_time:164032ms step_avg:503.16ms
step:327/1775 train_time:164506ms step_avg:503.07ms
step:328/1775 train_time:164993ms step_avg:503.03ms
step:329/1775 train_time:165463ms step_avg:502.93ms
step:330/1775 train_time:165958ms step_avg:502.90ms
step:331/1775 train_time:166427ms step_avg:502.80ms
step:332/1775 train_time:166910ms step_avg:502.74ms
step:333/1775 train_time:167381ms step_avg:502.65ms
step:334/1775 train_time:167855ms step_avg:502.56ms
step:335/1775 train_time:168330ms step_avg:502.48ms
step:336/1775 train_time:168817ms step_avg:502.43ms
step:337/1775 train_time:169306ms step_avg:502.39ms
step:338/1775 train_time:169780ms step_avg:502.31ms
step:339/1775 train_time:170257ms step_avg:502.23ms
step:340/1775 train_time:170742ms step_avg:502.18ms
step:341/1775 train_time:171219ms step_avg:502.11ms
step:342/1775 train_time:171684ms step_avg:502.00ms
step:343/1775 train_time:172154ms step_avg:501.91ms
step:344/1775 train_time:172637ms step_avg:501.85ms
step:345/1775 train_time:173114ms step_avg:501.78ms
step:346/1775 train_time:173605ms step_avg:501.75ms
step:347/1775 train_time:174090ms step_avg:501.70ms
step:348/1775 train_time:174577ms step_avg:501.66ms
step:349/1775 train_time:175072ms step_avg:501.64ms
step:350/1775 train_time:175562ms step_avg:501.61ms
step:351/1775 train_time:176057ms step_avg:501.59ms
step:352/1775 train_time:176539ms step_avg:501.53ms
step:353/1775 train_time:177027ms step_avg:501.49ms
step:354/1775 train_time:177505ms step_avg:501.43ms
step:355/1775 train_time:178063ms step_avg:501.59ms
step:356/1775 train_time:178603ms step_avg:501.69ms
step:357/1775 train_time:179094ms step_avg:501.66ms
step:358/1775 train_time:179630ms step_avg:501.76ms
step:359/1775 train_time:180159ms step_avg:501.84ms
step:360/1775 train_time:180708ms step_avg:501.97ms
step:361/1775 train_time:181229ms step_avg:502.02ms
step:362/1775 train_time:181717ms step_avg:501.98ms
step:363/1775 train_time:182199ms step_avg:501.92ms
step:364/1775 train_time:182702ms step_avg:501.93ms
step:365/1775 train_time:183185ms step_avg:501.88ms
step:366/1775 train_time:183673ms step_avg:501.84ms
step:367/1775 train_time:184153ms step_avg:501.78ms
step:368/1775 train_time:184646ms step_avg:501.76ms
step:369/1775 train_time:185115ms step_avg:501.67ms
step:370/1775 train_time:185595ms step_avg:501.61ms
step:371/1775 train_time:186074ms step_avg:501.55ms
step:372/1775 train_time:186570ms step_avg:501.53ms
step:373/1775 train_time:187050ms step_avg:501.47ms
step:374/1775 train_time:187522ms step_avg:501.40ms
step:375/1775 train_time:188001ms step_avg:501.34ms
step:376/1775 train_time:188477ms step_avg:501.27ms
step:377/1775 train_time:188962ms step_avg:501.23ms
step:378/1775 train_time:189465ms step_avg:501.23ms
step:379/1775 train_time:189981ms step_avg:501.27ms
step:380/1775 train_time:190489ms step_avg:501.29ms
step:381/1775 train_time:191024ms step_avg:501.38ms
step:382/1775 train_time:191506ms step_avg:501.32ms
step:383/1775 train_time:192044ms step_avg:501.42ms
step:384/1775 train_time:192545ms step_avg:501.42ms
step:385/1775 train_time:193088ms step_avg:501.53ms
step:386/1775 train_time:193624ms step_avg:501.62ms
step:387/1775 train_time:194134ms step_avg:501.64ms
step:388/1775 train_time:194646ms step_avg:501.66ms
step:389/1775 train_time:195140ms step_avg:501.64ms
step:390/1775 train_time:195649ms step_avg:501.66ms
step:391/1775 train_time:196166ms step_avg:501.70ms
step:392/1775 train_time:196691ms step_avg:501.76ms
step:393/1775 train_time:197199ms step_avg:501.78ms
step:394/1775 train_time:197729ms step_avg:501.85ms
step:395/1775 train_time:198254ms step_avg:501.91ms
step:396/1775 train_time:198774ms step_avg:501.95ms
step:397/1775 train_time:199278ms step_avg:501.96ms
step:398/1775 train_time:199794ms step_avg:501.99ms
step:399/1775 train_time:200307ms step_avg:502.02ms
step:400/1775 train_time:200822ms step_avg:502.06ms
step:401/1775 train_time:201314ms step_avg:502.03ms
step:402/1775 train_time:201824ms step_avg:502.05ms
step:403/1775 train_time:202297ms step_avg:501.98ms
step:404/1775 train_time:202781ms step_avg:501.93ms
step:405/1775 train_time:203270ms step_avg:501.90ms
step:406/1775 train_time:203769ms step_avg:501.89ms
step:407/1775 train_time:204289ms step_avg:501.94ms
step:408/1775 train_time:204796ms step_avg:501.95ms
step:409/1775 train_time:205273ms step_avg:501.89ms
step:410/1775 train_time:205743ms step_avg:501.81ms
step:411/1775 train_time:206208ms step_avg:501.72ms
step:412/1775 train_time:206699ms step_avg:501.70ms
step:413/1775 train_time:207174ms step_avg:501.63ms
step:414/1775 train_time:207693ms step_avg:501.67ms
step:415/1775 train_time:208186ms step_avg:501.65ms
step:416/1775 train_time:208678ms step_avg:501.63ms
step:417/1775 train_time:209141ms step_avg:501.54ms
step:418/1775 train_time:209622ms step_avg:501.49ms
step:419/1775 train_time:210114ms step_avg:501.47ms
step:420/1775 train_time:210625ms step_avg:501.49ms
step:421/1775 train_time:211103ms step_avg:501.43ms
step:422/1775 train_time:211596ms step_avg:501.41ms
step:423/1775 train_time:212081ms step_avg:501.37ms
step:424/1775 train_time:212570ms step_avg:501.34ms
step:425/1775 train_time:213048ms step_avg:501.29ms
step:426/1775 train_time:213521ms step_avg:501.22ms
step:427/1775 train_time:213988ms step_avg:501.14ms
step:428/1775 train_time:214481ms step_avg:501.12ms
step:429/1775 train_time:214966ms step_avg:501.09ms
step:430/1775 train_time:215450ms step_avg:501.05ms
step:431/1775 train_time:215950ms step_avg:501.04ms
step:432/1775 train_time:216436ms step_avg:501.01ms
step:433/1775 train_time:216907ms step_avg:500.94ms
step:434/1775 train_time:217384ms step_avg:500.88ms
step:435/1775 train_time:217874ms step_avg:500.86ms
step:436/1775 train_time:218384ms step_avg:500.88ms
step:437/1775 train_time:218919ms step_avg:500.96ms
step:438/1775 train_time:219446ms step_avg:501.02ms
step:439/1775 train_time:219928ms step_avg:500.98ms
step:440/1775 train_time:220431ms step_avg:500.98ms
step:441/1775 train_time:220960ms step_avg:501.04ms
step:442/1775 train_time:221485ms step_avg:501.10ms
step:443/1775 train_time:221986ms step_avg:501.10ms
step:444/1775 train_time:222535ms step_avg:501.21ms
step:445/1775 train_time:223087ms step_avg:501.32ms
step:446/1775 train_time:223564ms step_avg:501.26ms
step:447/1775 train_time:224031ms step_avg:501.19ms
step:448/1775 train_time:224527ms step_avg:501.18ms
step:449/1775 train_time:225002ms step_avg:501.12ms
step:450/1775 train_time:225476ms step_avg:501.06ms
step:451/1775 train_time:225948ms step_avg:500.99ms
step:452/1775 train_time:226423ms step_avg:500.94ms
step:453/1775 train_time:226889ms step_avg:500.86ms
step:454/1775 train_time:227368ms step_avg:500.81ms
step:455/1775 train_time:227863ms step_avg:500.80ms
step:456/1775 train_time:228338ms step_avg:500.74ms
step:457/1775 train_time:228832ms step_avg:500.73ms
step:458/1775 train_time:229338ms step_avg:500.74ms
step:459/1775 train_time:229835ms step_avg:500.73ms
step:460/1775 train_time:230298ms step_avg:500.65ms
step:461/1775 train_time:230822ms step_avg:500.70ms
step:462/1775 train_time:231386ms step_avg:500.84ms
step:463/1775 train_time:231864ms step_avg:500.79ms
step:464/1775 train_time:232353ms step_avg:500.76ms
step:465/1775 train_time:232836ms step_avg:500.72ms
step:466/1775 train_time:233325ms step_avg:500.70ms
step:467/1775 train_time:233836ms step_avg:500.72ms
step:468/1775 train_time:234406ms step_avg:500.87ms
step:469/1775 train_time:234972ms step_avg:501.01ms
step:470/1775 train_time:235555ms step_avg:501.18ms
step:471/1775 train_time:236072ms step_avg:501.21ms
step:472/1775 train_time:236598ms step_avg:501.27ms
step:473/1775 train_time:237150ms step_avg:501.37ms
step:474/1775 train_time:237758ms step_avg:501.60ms
step:475/1775 train_time:238332ms step_avg:501.75ms
step:476/1775 train_time:238923ms step_avg:501.94ms
step:477/1775 train_time:239487ms step_avg:502.07ms
step:478/1775 train_time:240030ms step_avg:502.15ms
step:479/1775 train_time:240548ms step_avg:502.19ms
step:480/1775 train_time:241073ms step_avg:502.24ms
step:481/1775 train_time:241575ms step_avg:502.24ms
step:482/1775 train_time:242091ms step_avg:502.26ms
step:483/1775 train_time:242581ms step_avg:502.24ms
step:484/1775 train_time:243078ms step_avg:502.23ms
step:485/1775 train_time:243609ms step_avg:502.29ms
step:486/1775 train_time:244125ms step_avg:502.31ms
step:487/1775 train_time:244611ms step_avg:502.28ms
step:488/1775 train_time:245087ms step_avg:502.23ms
step:489/1775 train_time:245566ms step_avg:502.18ms
step:490/1775 train_time:246065ms step_avg:502.17ms
step:491/1775 train_time:246558ms step_avg:502.15ms
step:492/1775 train_time:247038ms step_avg:502.11ms
step:493/1775 train_time:247524ms step_avg:502.08ms
step:494/1775 train_time:248010ms step_avg:502.04ms
step:495/1775 train_time:248502ms step_avg:502.02ms
step:496/1775 train_time:248994ms step_avg:502.00ms
step:497/1775 train_time:249465ms step_avg:501.94ms
step:498/1775 train_time:249945ms step_avg:501.90ms
step:499/1775 train_time:250432ms step_avg:501.87ms
step:500/1775 train_time:250940ms step_avg:501.88ms
step:500/1775 val_loss:4.2686 val_malbo_loss:4.2385 train_time:250947ms step_avg:501.89ms
step:501/1775 train_time:251421ms step_avg:501.84ms
step:502/1775 train_time:251903ms step_avg:501.80ms
step:503/1775 train_time:252396ms step_avg:501.78ms
step:504/1775 train_time:252885ms step_avg:501.76ms
step:505/1775 train_time:253354ms step_avg:501.69ms
step:506/1775 train_time:253833ms step_avg:501.65ms
step:507/1775 train_time:254325ms step_avg:501.63ms
step:508/1775 train_time:254805ms step_avg:501.58ms
step:509/1775 train_time:255278ms step_avg:501.53ms
step:510/1775 train_time:255765ms step_avg:501.50ms
step:511/1775 train_time:256256ms step_avg:501.48ms
step:512/1775 train_time:256746ms step_avg:501.46ms
step:513/1775 train_time:257266ms step_avg:501.49ms
step:514/1775 train_time:257761ms step_avg:501.48ms
step:515/1775 train_time:258265ms step_avg:501.48ms
step:516/1775 train_time:258764ms step_avg:501.48ms
step:517/1775 train_time:259257ms step_avg:501.46ms
step:518/1775 train_time:259759ms step_avg:501.47ms
step:519/1775 train_time:260274ms step_avg:501.49ms
step:520/1775 train_time:260797ms step_avg:501.53ms
step:521/1775 train_time:261328ms step_avg:501.59ms
step:522/1775 train_time:261855ms step_avg:501.64ms
step:523/1775 train_time:262406ms step_avg:501.73ms
step:524/1775 train_time:262941ms step_avg:501.80ms
step:525/1775 train_time:263448ms step_avg:501.81ms
step:526/1775 train_time:263901ms step_avg:501.71ms
step:527/1775 train_time:264426ms step_avg:501.76ms
step:528/1775 train_time:264960ms step_avg:501.82ms
step:529/1775 train_time:265471ms step_avg:501.84ms
step:530/1775 train_time:266017ms step_avg:501.92ms
step:531/1775 train_time:266553ms step_avg:501.98ms
step:532/1775 train_time:267116ms step_avg:502.10ms
step:533/1775 train_time:267720ms step_avg:502.29ms
step:534/1775 train_time:268273ms step_avg:502.38ms
step:535/1775 train_time:268864ms step_avg:502.55ms
step:536/1775 train_time:269456ms step_avg:502.72ms
step:537/1775 train_time:270037ms step_avg:502.86ms
step:538/1775 train_time:270564ms step_avg:502.91ms
step:539/1775 train_time:271097ms step_avg:502.96ms
step:540/1775 train_time:271635ms step_avg:503.03ms
step:541/1775 train_time:272105ms step_avg:502.97ms
step:542/1775 train_time:272585ms step_avg:502.93ms
step:543/1775 train_time:273061ms step_avg:502.88ms
step:544/1775 train_time:273546ms step_avg:502.84ms
step:545/1775 train_time:274026ms step_avg:502.80ms
step:546/1775 train_time:274517ms step_avg:502.78ms
step:547/1775 train_time:274990ms step_avg:502.72ms
step:548/1775 train_time:275492ms step_avg:502.72ms
step:549/1775 train_time:275976ms step_avg:502.69ms
step:550/1775 train_time:276454ms step_avg:502.64ms
step:551/1775 train_time:276926ms step_avg:502.59ms
step:552/1775 train_time:277427ms step_avg:502.58ms
step:553/1775 train_time:277904ms step_avg:502.54ms
step:554/1775 train_time:278388ms step_avg:502.51ms
step:555/1775 train_time:278875ms step_avg:502.48ms
step:556/1775 train_time:279374ms step_avg:502.47ms
step:557/1775 train_time:279847ms step_avg:502.42ms
step:558/1775 train_time:280375ms step_avg:502.46ms
step:559/1775 train_time:280881ms step_avg:502.47ms
step:560/1775 train_time:281448ms step_avg:502.59ms
step:561/1775 train_time:282023ms step_avg:502.72ms
step:562/1775 train_time:282548ms step_avg:502.75ms
step:563/1775 train_time:283089ms step_avg:502.82ms
step:564/1775 train_time:283623ms step_avg:502.88ms
step:565/1775 train_time:284194ms step_avg:503.00ms
step:566/1775 train_time:284789ms step_avg:503.16ms
step:567/1775 train_time:285312ms step_avg:503.20ms
step:568/1775 train_time:285826ms step_avg:503.22ms
step:569/1775 train_time:286322ms step_avg:503.20ms
step:570/1775 train_time:286838ms step_avg:503.23ms
step:571/1775 train_time:287369ms step_avg:503.27ms
step:572/1775 train_time:287905ms step_avg:503.33ms
step:573/1775 train_time:288430ms step_avg:503.37ms
step:574/1775 train_time:288928ms step_avg:503.36ms
step:575/1775 train_time:289425ms step_avg:503.35ms
step:576/1775 train_time:289954ms step_avg:503.39ms
step:577/1775 train_time:290498ms step_avg:503.46ms
step:578/1775 train_time:290999ms step_avg:503.46ms
step:579/1775 train_time:291504ms step_avg:503.46ms
step:580/1775 train_time:426855ms step_avg:735.96ms
step:581/1775 train_time:427647ms step_avg:736.05ms
step:582/1775 train_time:428430ms step_avg:736.13ms
step:583/1775 train_time:429212ms step_avg:736.21ms
step:584/1775 train_time:429997ms step_avg:736.30ms
step:585/1775 train_time:430776ms step_avg:736.37ms
step:586/1775 train_time:431562ms step_avg:736.45ms
step:587/1775 train_time:432347ms step_avg:736.54ms
step:588/1775 train_time:433154ms step_avg:736.66ms
step:589/1775 train_time:433933ms step_avg:736.73ms
step:590/1775 train_time:434723ms step_avg:736.82ms
step:591/1775 train_time:435502ms step_avg:736.89ms
step:592/1775 train_time:436293ms step_avg:736.98ms
step:593/1775 train_time:437074ms step_avg:737.06ms
step:594/1775 train_time:437863ms step_avg:737.14ms
step:595/1775 train_time:438654ms step_avg:737.23ms
step:596/1775 train_time:439449ms step_avg:737.33ms
step:597/1775 train_time:440239ms step_avg:737.42ms
step:598/1775 train_time:441033ms step_avg:737.51ms
step:599/1775 train_time:441818ms step_avg:737.59ms
step:600/1775 train_time:442604ms step_avg:737.67ms
step:601/1775 train_time:443387ms step_avg:737.75ms
step:602/1775 train_time:444370ms step_avg:738.16ms
step:603/1775 train_time:445156ms step_avg:738.23ms
step:604/1775 train_time:445956ms step_avg:738.34ms
step:605/1775 train_time:446745ms step_avg:738.42ms
step:606/1775 train_time:447542ms step_avg:738.52ms
step:607/1775 train_time:448308ms step_avg:738.56ms
step:608/1775 train_time:449095ms step_avg:738.64ms
step:609/1775 train_time:449870ms step_avg:738.70ms
step:610/1775 train_time:450658ms step_avg:738.78ms
step:611/1775 train_time:451437ms step_avg:738.85ms
step:612/1775 train_time:452236ms step_avg:738.95ms
step:613/1775 train_time:453018ms step_avg:739.02ms
step:614/1775 train_time:453807ms step_avg:739.10ms
step:615/1775 train_time:454585ms step_avg:739.16ms
step:616/1775 train_time:455370ms step_avg:739.24ms
step:617/1775 train_time:456150ms step_avg:739.30ms
step:618/1775 train_time:456938ms step_avg:739.38ms
step:619/1775 train_time:457726ms step_avg:739.46ms
step:620/1775 train_time:458517ms step_avg:739.54ms
step:621/1775 train_time:459296ms step_avg:739.61ms
step:622/1775 train_time:460082ms step_avg:739.68ms
step:623/1775 train_time:460863ms step_avg:739.75ms
step:624/1775 train_time:461646ms step_avg:739.82ms
step:625/1775 train_time:462429ms step_avg:739.89ms
step:626/1775 train_time:463215ms step_avg:739.96ms
step:627/1775 train_time:463997ms step_avg:740.03ms
step:628/1775 train_time:464786ms step_avg:740.10ms
step:629/1775 train_time:465566ms step_avg:740.17ms
step:630/1775 train_time:466348ms step_avg:740.23ms
step:631/1775 train_time:467135ms step_avg:740.31ms
step:632/1775 train_time:467929ms step_avg:740.39ms
step:633/1775 train_time:468710ms step_avg:740.46ms
step:634/1775 train_time:469498ms step_avg:740.53ms
step:635/1775 train_time:470281ms step_avg:740.60ms
step:636/1775 train_time:471068ms step_avg:740.67ms
step:637/1775 train_time:471846ms step_avg:740.73ms
step:638/1775 train_time:472636ms step_avg:740.81ms
step:639/1775 train_time:473431ms step_avg:740.89ms
step:640/1775 train_time:474217ms step_avg:740.96ms
step:641/1775 train_time:475003ms step_avg:741.03ms
step:642/1775 train_time:475790ms step_avg:741.11ms
step:643/1775 train_time:476570ms step_avg:741.17ms
step:644/1775 train_time:477353ms step_avg:741.23ms
step:645/1775 train_time:478138ms step_avg:741.30ms
step:646/1775 train_time:478939ms step_avg:741.39ms
step:647/1775 train_time:479726ms step_avg:741.46ms
step:648/1775 train_time:480514ms step_avg:741.53ms
step:649/1775 train_time:481298ms step_avg:741.60ms
step:650/1775 train_time:482088ms step_avg:741.67ms
step:651/1775 train_time:482872ms step_avg:741.74ms
step:652/1775 train_time:483656ms step_avg:741.80ms
step:653/1775 train_time:484438ms step_avg:741.87ms
step:654/1775 train_time:485235ms step_avg:741.95ms
step:655/1775 train_time:486017ms step_avg:742.01ms
step:656/1775 train_time:486814ms step_avg:742.09ms
step:657/1775 train_time:487597ms step_avg:742.16ms
step:658/1775 train_time:488382ms step_avg:742.22ms
step:659/1775 train_time:489172ms step_avg:742.29ms
step:660/1775 train_time:489960ms step_avg:742.36ms
step:661/1775 train_time:490739ms step_avg:742.42ms
step:662/1775 train_time:491533ms step_avg:742.50ms
step:663/1775 train_time:492320ms step_avg:742.56ms
step:664/1775 train_time:493108ms step_avg:742.63ms
step:665/1775 train_time:493886ms step_avg:742.69ms
step:666/1775 train_time:494675ms step_avg:742.76ms
step:667/1775 train_time:495457ms step_avg:742.81ms
step:668/1775 train_time:496244ms step_avg:742.88ms
step:669/1775 train_time:497036ms step_avg:742.95ms
step:670/1775 train_time:497837ms step_avg:743.04ms
step:671/1775 train_time:498621ms step_avg:743.10ms
step:672/1775 train_time:499415ms step_avg:743.18ms
step:673/1775 train_time:500189ms step_avg:743.22ms
step:674/1775 train_time:500980ms step_avg:743.29ms
step:675/1775 train_time:501768ms step_avg:743.36ms
step:676/1775 train_time:502553ms step_avg:743.42ms
step:677/1775 train_time:503335ms step_avg:743.48ms
step:678/1775 train_time:504136ms step_avg:743.56ms
step:679/1775 train_time:504920ms step_avg:743.62ms
step:680/1775 train_time:505711ms step_avg:743.69ms
step:681/1775 train_time:506496ms step_avg:743.75ms
step:682/1775 train_time:507281ms step_avg:743.81ms
step:683/1775 train_time:508067ms step_avg:743.88ms
step:684/1775 train_time:508850ms step_avg:743.93ms
step:685/1775 train_time:509636ms step_avg:743.99ms
step:686/1775 train_time:510433ms step_avg:744.07ms
step:687/1775 train_time:511217ms step_avg:744.13ms
step:688/1775 train_time:512014ms step_avg:744.21ms
step:689/1775 train_time:512795ms step_avg:744.26ms
step:690/1775 train_time:513583ms step_avg:744.32ms
step:691/1775 train_time:514370ms step_avg:744.39ms
step:692/1775 train_time:515155ms step_avg:744.44ms
step:693/1775 train_time:515942ms step_avg:744.50ms
step:694/1775 train_time:516736ms step_avg:744.58ms
step:695/1775 train_time:517524ms step_avg:744.64ms
step:696/1775 train_time:518316ms step_avg:744.71ms
step:697/1775 train_time:519098ms step_avg:744.76ms
step:698/1775 train_time:519887ms step_avg:744.82ms
step:699/1775 train_time:520675ms step_avg:744.88ms
step:700/1775 train_time:521462ms step_avg:744.95ms
step:701/1775 train_time:522243ms step_avg:745.00ms
step:702/1775 train_time:523041ms step_avg:745.07ms
step:703/1775 train_time:523836ms step_avg:745.14ms
step:704/1775 train_time:524631ms step_avg:745.21ms
step:705/1775 train_time:525415ms step_avg:745.27ms
step:706/1775 train_time:526207ms step_avg:745.34ms
step:707/1775 train_time:526995ms step_avg:745.40ms
step:708/1775 train_time:527782ms step_avg:745.45ms
step:709/1775 train_time:528572ms step_avg:745.52ms
step:710/1775 train_time:529358ms step_avg:745.57ms
step:711/1775 train_time:530140ms step_avg:745.63ms
step:712/1775 train_time:530935ms step_avg:745.69ms
step:713/1775 train_time:531721ms step_avg:745.75ms
step:714/1775 train_time:532511ms step_avg:745.81ms
step:715/1775 train_time:533295ms step_avg:745.87ms
step:716/1775 train_time:534081ms step_avg:745.92ms
step:717/1775 train_time:534871ms step_avg:745.98ms
step:718/1775 train_time:535658ms step_avg:746.04ms
step:719/1775 train_time:536441ms step_avg:746.09ms
step:720/1775 train_time:537237ms step_avg:746.16ms
step:721/1775 train_time:538037ms step_avg:746.24ms
step:722/1775 train_time:538829ms step_avg:746.30ms
step:723/1775 train_time:539609ms step_avg:746.35ms
step:724/1775 train_time:540396ms step_avg:746.40ms
step:725/1775 train_time:541179ms step_avg:746.45ms
step:726/1775 train_time:541975ms step_avg:746.52ms
step:727/1775 train_time:542759ms step_avg:746.57ms
step:728/1775 train_time:543544ms step_avg:746.63ms
step:729/1775 train_time:544333ms step_avg:746.68ms
step:730/1775 train_time:545133ms step_avg:746.76ms
step:731/1775 train_time:545917ms step_avg:746.81ms
step:732/1775 train_time:546708ms step_avg:746.87ms
step:733/1775 train_time:547491ms step_avg:746.92ms
step:734/1775 train_time:548280ms step_avg:746.98ms
step:735/1775 train_time:549064ms step_avg:747.03ms
step:736/1775 train_time:549848ms step_avg:747.08ms
step:737/1775 train_time:550641ms step_avg:747.14ms
step:738/1775 train_time:551433ms step_avg:747.20ms
step:739/1775 train_time:552221ms step_avg:747.25ms
step:740/1775 train_time:553015ms step_avg:747.32ms
step:741/1775 train_time:553799ms step_avg:747.37ms
step:742/1775 train_time:554587ms step_avg:747.42ms
step:743/1775 train_time:555376ms step_avg:747.48ms
step:744/1775 train_time:556165ms step_avg:747.53ms
step:745/1775 train_time:556949ms step_avg:747.58ms
step:746/1775 train_time:557741ms step_avg:747.64ms
step:747/1775 train_time:558533ms step_avg:747.70ms
step:748/1775 train_time:559322ms step_avg:747.76ms
step:749/1775 train_time:560111ms step_avg:747.81ms
step:750/1775 train_time:560896ms step_avg:747.86ms
step:750/1775 val_loss:3.9901 val_malbo_loss:3.9608 train_time:560945ms step_avg:747.93ms
step:751/1775 train_time:561697ms step_avg:747.93ms
step:752/1775 train_time:562484ms step_avg:747.98ms
step:753/1775 train_time:563272ms step_avg:748.04ms
step:754/1775 train_time:564067ms step_avg:748.10ms
step:755/1775 train_time:564855ms step_avg:748.15ms
step:756/1775 train_time:565642ms step_avg:748.20ms
step:757/1775 train_time:566420ms step_avg:748.24ms
step:758/1775 train_time:567209ms step_avg:748.30ms
step:759/1775 train_time:567999ms step_avg:748.35ms
step:760/1775 train_time:568782ms step_avg:748.40ms
step:761/1775 train_time:569567ms step_avg:748.44ms
step:762/1775 train_time:570368ms step_avg:748.51ms
step:763/1775 train_time:571153ms step_avg:748.56ms
step:764/1775 train_time:571940ms step_avg:748.61ms
step:765/1775 train_time:572723ms step_avg:748.66ms
step:766/1775 train_time:573516ms step_avg:748.72ms
step:767/1775 train_time:574304ms step_avg:748.77ms
step:768/1775 train_time:575089ms step_avg:748.81ms
step:769/1775 train_time:575869ms step_avg:748.85ms
step:770/1775 train_time:576671ms step_avg:748.92ms
step:771/1775 train_time:577468ms step_avg:748.99ms
step:772/1775 train_time:578269ms step_avg:749.05ms
step:773/1775 train_time:579057ms step_avg:749.10ms
step:774/1775 train_time:579847ms step_avg:749.16ms
step:775/1775 train_time:580632ms step_avg:749.20ms
step:776/1775 train_time:581420ms step_avg:749.25ms
step:777/1775 train_time:582206ms step_avg:749.30ms
step:778/1775 train_time:582997ms step_avg:749.35ms
step:779/1775 train_time:583786ms step_avg:749.40ms
step:780/1775 train_time:584575ms step_avg:749.45ms
step:781/1775 train_time:585369ms step_avg:749.51ms
step:782/1775 train_time:586168ms step_avg:749.58ms
step:783/1775 train_time:586962ms step_avg:749.63ms
step:784/1775 train_time:587769ms step_avg:749.71ms
step:785/1775 train_time:588550ms step_avg:749.75ms
step:786/1775 train_time:589340ms step_avg:749.80ms
step:787/1775 train_time:590121ms step_avg:749.84ms
step:788/1775 train_time:590914ms step_avg:749.89ms
step:789/1775 train_time:591703ms step_avg:749.94ms
step:790/1775 train_time:592496ms step_avg:749.99ms
step:791/1775 train_time:593279ms step_avg:750.04ms
step:792/1775 train_time:594072ms step_avg:750.09ms
step:793/1775 train_time:594868ms step_avg:750.15ms
step:794/1775 train_time:595679ms step_avg:750.23ms
step:795/1775 train_time:596463ms step_avg:750.27ms
step:796/1775 train_time:597268ms step_avg:750.34ms
step:797/1775 train_time:598060ms step_avg:750.39ms
step:798/1775 train_time:598851ms step_avg:750.44ms
step:799/1775 train_time:599641ms step_avg:750.49ms
step:800/1775 train_time:600437ms step_avg:750.55ms
step:801/1775 train_time:601224ms step_avg:750.59ms
step:802/1775 train_time:601994ms step_avg:750.62ms
step:803/1775 train_time:602782ms step_avg:750.66ms
step:804/1775 train_time:603565ms step_avg:750.70ms
step:805/1775 train_time:604351ms step_avg:750.75ms
step:806/1775 train_time:605147ms step_avg:750.80ms
step:807/1775 train_time:605939ms step_avg:750.85ms
step:808/1775 train_time:606734ms step_avg:750.91ms
step:809/1775 train_time:607516ms step_avg:750.95ms
step:810/1775 train_time:608305ms step_avg:750.99ms
step:811/1775 train_time:609087ms step_avg:751.03ms
step:812/1775 train_time:609873ms step_avg:751.08ms
step:813/1775 train_time:610655ms step_avg:751.11ms
step:814/1775 train_time:611447ms step_avg:751.16ms
step:815/1775 train_time:612232ms step_avg:751.20ms
step:816/1775 train_time:613022ms step_avg:751.25ms
step:817/1775 train_time:613805ms step_avg:751.29ms
step:818/1775 train_time:614591ms step_avg:751.33ms
step:819/1775 train_time:615379ms step_avg:751.38ms
step:820/1775 train_time:616171ms step_avg:751.43ms
step:821/1775 train_time:616954ms step_avg:751.47ms
step:822/1775 train_time:617759ms step_avg:751.53ms
step:823/1775 train_time:618548ms step_avg:751.58ms
step:824/1775 train_time:619342ms step_avg:751.63ms
step:825/1775 train_time:620126ms step_avg:751.67ms
step:826/1775 train_time:620915ms step_avg:751.71ms
step:827/1775 train_time:621693ms step_avg:751.75ms
step:828/1775 train_time:622486ms step_avg:751.79ms
step:829/1775 train_time:623266ms step_avg:751.83ms
step:830/1775 train_time:624054ms step_avg:751.87ms
step:831/1775 train_time:624847ms step_avg:751.92ms
step:832/1775 train_time:625639ms step_avg:751.97ms
step:833/1775 train_time:626424ms step_avg:752.01ms
step:834/1775 train_time:627209ms step_avg:752.05ms
step:835/1775 train_time:627993ms step_avg:752.09ms
step:836/1775 train_time:628784ms step_avg:752.13ms
step:837/1775 train_time:629564ms step_avg:752.17ms
step:838/1775 train_time:630352ms step_avg:752.21ms
step:839/1775 train_time:631142ms step_avg:752.26ms
step:840/1775 train_time:631931ms step_avg:752.30ms
step:841/1775 train_time:632713ms step_avg:752.33ms
step:842/1775 train_time:633503ms step_avg:752.38ms
step:843/1775 train_time:634282ms step_avg:752.41ms
step:844/1775 train_time:635068ms step_avg:752.45ms
step:845/1775 train_time:635853ms step_avg:752.49ms
step:846/1775 train_time:636651ms step_avg:752.54ms
step:847/1775 train_time:637440ms step_avg:752.59ms
step:848/1775 train_time:638229ms step_avg:752.63ms
step:849/1775 train_time:639014ms step_avg:752.67ms
step:850/1775 train_time:639803ms step_avg:752.71ms
step:851/1775 train_time:640585ms step_avg:752.74ms
step:852/1775 train_time:641372ms step_avg:752.78ms
step:853/1775 train_time:642153ms step_avg:752.82ms
step:854/1775 train_time:642950ms step_avg:752.87ms
step:855/1775 train_time:643740ms step_avg:752.91ms
step:856/1775 train_time:644527ms step_avg:752.95ms
step:857/1775 train_time:645317ms step_avg:753.00ms
step:858/1775 train_time:646109ms step_avg:753.04ms
step:859/1775 train_time:646890ms step_avg:753.07ms
step:860/1775 train_time:647678ms step_avg:753.11ms
step:861/1775 train_time:648459ms step_avg:753.15ms
step:862/1775 train_time:649254ms step_avg:753.19ms
step:863/1775 train_time:650046ms step_avg:753.24ms
step:864/1775 train_time:650836ms step_avg:753.28ms
step:865/1775 train_time:651622ms step_avg:753.32ms
step:866/1775 train_time:652410ms step_avg:753.36ms
step:867/1775 train_time:653193ms step_avg:753.39ms
step:868/1775 train_time:653983ms step_avg:753.44ms
step:869/1775 train_time:654766ms step_avg:753.47ms
step:870/1775 train_time:655557ms step_avg:753.51ms
step:871/1775 train_time:656357ms step_avg:753.57ms
step:872/1775 train_time:657155ms step_avg:753.62ms
step:873/1775 train_time:657947ms step_avg:753.66ms
step:874/1775 train_time:658740ms step_avg:753.71ms
step:875/1775 train_time:659527ms step_avg:753.74ms
step:876/1775 train_time:660314ms step_avg:753.78ms
step:877/1775 train_time:661099ms step_avg:753.82ms
step:878/1775 train_time:661888ms step_avg:753.86ms
step:879/1775 train_time:662671ms step_avg:753.89ms
step:880/1775 train_time:663458ms step_avg:753.93ms
step:881/1775 train_time:664248ms step_avg:753.97ms
step:882/1775 train_time:665043ms step_avg:754.02ms
step:883/1775 train_time:665828ms step_avg:754.05ms
step:884/1775 train_time:666615ms step_avg:754.09ms
step:885/1775 train_time:667403ms step_avg:754.13ms
step:886/1775 train_time:668191ms step_avg:754.17ms
step:887/1775 train_time:668978ms step_avg:754.20ms
step:888/1775 train_time:669763ms step_avg:754.24ms
step:889/1775 train_time:670549ms step_avg:754.27ms
step:890/1775 train_time:671347ms step_avg:754.32ms
step:891/1775 train_time:672132ms step_avg:754.36ms
step:892/1775 train_time:672922ms step_avg:754.40ms
step:893/1775 train_time:673702ms step_avg:754.43ms
step:894/1775 train_time:674491ms step_avg:754.46ms
step:895/1775 train_time:675279ms step_avg:754.50ms
step:896/1775 train_time:676063ms step_avg:754.53ms
step:897/1775 train_time:676851ms step_avg:754.57ms
step:898/1775 train_time:677649ms step_avg:754.62ms
step:899/1775 train_time:678438ms step_avg:754.66ms
step:900/1775 train_time:679230ms step_avg:754.70ms
step:901/1775 train_time:680013ms step_avg:754.73ms
step:902/1775 train_time:680801ms step_avg:754.77ms
step:903/1775 train_time:681584ms step_avg:754.80ms
step:904/1775 train_time:682368ms step_avg:754.83ms
step:905/1775 train_time:683153ms step_avg:754.87ms
step:906/1775 train_time:683951ms step_avg:754.91ms
step:907/1775 train_time:684743ms step_avg:754.95ms
step:908/1775 train_time:685539ms step_avg:755.00ms
step:909/1775 train_time:686329ms step_avg:755.04ms
step:910/1775 train_time:687119ms step_avg:755.08ms
step:911/1775 train_time:687904ms step_avg:755.11ms
step:912/1775 train_time:688695ms step_avg:755.15ms
step:913/1775 train_time:689481ms step_avg:755.18ms
step:914/1775 train_time:690265ms step_avg:755.21ms
step:915/1775 train_time:691052ms step_avg:755.25ms
step:916/1775 train_time:691849ms step_avg:755.29ms
step:917/1775 train_time:692637ms step_avg:755.33ms
step:918/1775 train_time:693424ms step_avg:755.36ms
step:919/1775 train_time:694385ms step_avg:755.59ms
step:920/1775 train_time:695181ms step_avg:755.63ms
step:921/1775 train_time:695967ms step_avg:755.66ms
step:922/1775 train_time:696776ms step_avg:755.72ms
step:923/1775 train_time:697575ms step_avg:755.77ms
step:924/1775 train_time:698380ms step_avg:755.82ms
step:925/1775 train_time:699176ms step_avg:755.87ms
step:926/1775 train_time:699971ms step_avg:755.91ms
step:927/1775 train_time:700766ms step_avg:755.95ms
step:928/1775 train_time:701571ms step_avg:756.00ms
step:929/1775 train_time:702370ms step_avg:756.05ms
step:930/1775 train_time:703176ms step_avg:756.10ms
step:931/1775 train_time:703967ms step_avg:756.14ms
step:932/1775 train_time:704772ms step_avg:756.19ms
step:933/1775 train_time:705570ms step_avg:756.24ms
step:934/1775 train_time:706376ms step_avg:756.29ms
step:935/1775 train_time:707168ms step_avg:756.33ms
step:936/1775 train_time:707972ms step_avg:756.38ms
step:937/1775 train_time:708766ms step_avg:756.42ms
step:938/1775 train_time:709570ms step_avg:756.47ms
step:939/1775 train_time:710371ms step_avg:756.52ms
step:940/1775 train_time:711176ms step_avg:756.57ms
step:941/1775 train_time:711967ms step_avg:756.61ms
step:942/1775 train_time:712774ms step_avg:756.66ms
step:943/1775 train_time:713559ms step_avg:756.69ms
step:944/1775 train_time:714373ms step_avg:756.75ms
step:945/1775 train_time:715172ms step_avg:756.80ms
step:946/1775 train_time:715975ms step_avg:756.84ms
step:947/1775 train_time:716767ms step_avg:756.88ms
step:948/1775 train_time:717576ms step_avg:756.94ms
step:949/1775 train_time:718367ms step_avg:756.97ms
step:950/1775 train_time:719173ms step_avg:757.02ms
step:951/1775 train_time:719968ms step_avg:757.06ms
step:952/1775 train_time:720773ms step_avg:757.11ms
step:953/1775 train_time:721581ms step_avg:757.17ms
step:954/1775 train_time:722383ms step_avg:757.22ms
step:955/1775 train_time:723170ms step_avg:757.25ms
step:956/1775 train_time:723981ms step_avg:757.30ms
step:957/1775 train_time:724772ms step_avg:757.34ms
step:958/1775 train_time:725579ms step_avg:757.39ms
step:959/1775 train_time:726376ms step_avg:757.43ms
step:960/1775 train_time:727175ms step_avg:757.47ms
step:961/1775 train_time:727972ms step_avg:757.52ms
step:962/1775 train_time:728774ms step_avg:757.56ms
step:963/1775 train_time:729571ms step_avg:757.60ms
step:964/1775 train_time:730373ms step_avg:757.65ms
step:965/1775 train_time:731173ms step_avg:757.69ms
step:966/1775 train_time:731970ms step_avg:757.73ms
step:967/1775 train_time:732766ms step_avg:757.77ms
step:968/1775 train_time:733576ms step_avg:757.83ms
step:969/1775 train_time:734371ms step_avg:757.87ms
step:970/1775 train_time:735174ms step_avg:757.91ms
step:971/1775 train_time:735971ms step_avg:757.95ms
step:972/1775 train_time:736780ms step_avg:758.00ms
step:973/1775 train_time:737569ms step_avg:758.04ms
step:974/1775 train_time:738374ms step_avg:758.08ms
step:975/1775 train_time:739172ms step_avg:758.12ms
step:976/1775 train_time:739971ms step_avg:758.17ms
step:977/1775 train_time:740772ms step_avg:758.21ms
step:978/1775 train_time:741571ms step_avg:758.25ms
step:979/1775 train_time:742367ms step_avg:758.29ms
step:980/1775 train_time:743171ms step_avg:758.34ms
step:981/1775 train_time:743969ms step_avg:758.38ms
step:982/1775 train_time:744775ms step_avg:758.43ms
step:983/1775 train_time:745568ms step_avg:758.46ms
step:984/1775 train_time:746369ms step_avg:758.51ms
step:985/1775 train_time:747167ms step_avg:758.54ms
step:986/1775 train_time:747971ms step_avg:758.59ms
step:987/1775 train_time:748768ms step_avg:758.63ms
step:988/1775 train_time:749573ms step_avg:758.68ms
step:989/1775 train_time:750372ms step_avg:758.72ms
step:990/1775 train_time:751175ms step_avg:758.76ms
step:991/1775 train_time:751970ms step_avg:758.80ms
step:992/1775 train_time:752773ms step_avg:758.84ms
step:993/1775 train_time:753568ms step_avg:758.88ms
step:994/1775 train_time:754374ms step_avg:758.93ms
step:995/1775 train_time:755180ms step_avg:758.98ms
step:996/1775 train_time:755977ms step_avg:759.01ms
step:997/1775 train_time:756773ms step_avg:759.05ms
step:998/1775 train_time:757572ms step_avg:759.09ms
step:999/1775 train_time:758368ms step_avg:759.13ms
step:1000/1775 train_time:759171ms step_avg:759.17ms
step:1000/1775 val_loss:3.7374 val_malbo_loss:3.7092 train_time:759204ms step_avg:759.20ms
step:1001/1775 train_time:759958ms step_avg:759.20ms
step:1002/1775 train_time:760752ms step_avg:759.23ms
step:1003/1775 train_time:761539ms step_avg:759.26ms
step:1004/1775 train_time:762342ms step_avg:759.30ms
step:1005/1775 train_time:763127ms step_avg:759.33ms
step:1006/1775 train_time:763916ms step_avg:759.36ms
step:1007/1775 train_time:764707ms step_avg:759.39ms
step:1008/1775 train_time:765511ms step_avg:759.44ms
step:1009/1775 train_time:766306ms step_avg:759.47ms
step:1010/1775 train_time:767105ms step_avg:759.51ms
step:1011/1775 train_time:767902ms step_avg:759.55ms
step:1012/1775 train_time:768694ms step_avg:759.58ms
step:1013/1775 train_time:769500ms step_avg:759.63ms
step:1014/1775 train_time:770303ms step_avg:759.67ms
step:1015/1775 train_time:771102ms step_avg:759.71ms
step:1016/1775 train_time:771908ms step_avg:759.75ms
step:1017/1775 train_time:772705ms step_avg:759.79ms
step:1018/1775 train_time:773509ms step_avg:759.83ms
step:1019/1775 train_time:774304ms step_avg:759.87ms
step:1020/1775 train_time:775107ms step_avg:759.91ms
step:1021/1775 train_time:775904ms step_avg:759.95ms
step:1022/1775 train_time:776709ms step_avg:759.99ms
step:1023/1775 train_time:777510ms step_avg:760.03ms
step:1024/1775 train_time:778317ms step_avg:760.08ms
step:1025/1775 train_time:779104ms step_avg:760.10ms
step:1026/1775 train_time:779907ms step_avg:760.14ms
step:1027/1775 train_time:780702ms step_avg:760.18ms
step:1028/1775 train_time:781507ms step_avg:760.22ms
step:1029/1775 train_time:782306ms step_avg:760.26ms
step:1030/1775 train_time:783107ms step_avg:760.30ms
step:1031/1775 train_time:783905ms step_avg:760.33ms
step:1032/1775 train_time:784709ms step_avg:760.38ms
step:1033/1775 train_time:785506ms step_avg:760.41ms
step:1034/1775 train_time:786305ms step_avg:760.45ms
step:1035/1775 train_time:787103ms step_avg:760.49ms
step:1036/1775 train_time:787912ms step_avg:760.53ms
step:1037/1775 train_time:788703ms step_avg:760.56ms
step:1038/1775 train_time:789508ms step_avg:760.60ms
step:1039/1775 train_time:790303ms step_avg:760.64ms
step:1040/1775 train_time:791107ms step_avg:760.68ms
step:1041/1775 train_time:791906ms step_avg:760.72ms
step:1042/1775 train_time:792706ms step_avg:760.75ms
step:1043/1775 train_time:793503ms step_avg:760.79ms
step:1044/1775 train_time:794308ms step_avg:760.83ms
step:1045/1775 train_time:795105ms step_avg:760.87ms
step:1046/1775 train_time:795909ms step_avg:760.91ms
step:1047/1775 train_time:796701ms step_avg:760.94ms
step:1048/1775 train_time:797507ms step_avg:760.98ms
step:1049/1775 train_time:798300ms step_avg:761.01ms
step:1050/1775 train_time:799103ms step_avg:761.05ms
step:1051/1775 train_time:799907ms step_avg:761.09ms
step:1052/1775 train_time:800710ms step_avg:761.13ms
step:1053/1775 train_time:801501ms step_avg:761.16ms
step:1054/1775 train_time:802304ms step_avg:761.20ms
step:1055/1775 train_time:803102ms step_avg:761.23ms
step:1056/1775 train_time:803908ms step_avg:761.28ms
step:1057/1775 train_time:804707ms step_avg:761.31ms
step:1058/1775 train_time:805509ms step_avg:761.35ms
step:1059/1775 train_time:806304ms step_avg:761.38ms
step:1060/1775 train_time:807113ms step_avg:761.43ms
step:1061/1775 train_time:807906ms step_avg:761.46ms
step:1062/1775 train_time:808718ms step_avg:761.50ms
step:1063/1775 train_time:809506ms step_avg:761.53ms
step:1064/1775 train_time:810312ms step_avg:761.57ms
step:1065/1775 train_time:811110ms step_avg:761.61ms
step:1066/1775 train_time:811915ms step_avg:761.65ms
step:1067/1775 train_time:812711ms step_avg:761.68ms
step:1068/1775 train_time:813506ms step_avg:761.71ms
step:1069/1775 train_time:814303ms step_avg:761.74ms
step:1070/1775 train_time:815107ms step_avg:761.78ms
step:1071/1775 train_time:815907ms step_avg:761.82ms
step:1072/1775 train_time:816710ms step_avg:761.86ms
step:1073/1775 train_time:817500ms step_avg:761.88ms
step:1074/1775 train_time:818305ms step_avg:761.92ms
step:1075/1775 train_time:819106ms step_avg:761.96ms
step:1076/1775 train_time:819908ms step_avg:762.00ms
step:1077/1775 train_time:820704ms step_avg:762.03ms
step:1078/1775 train_time:821507ms step_avg:762.07ms
step:1079/1775 train_time:822305ms step_avg:762.10ms
step:1080/1775 train_time:823114ms step_avg:762.14ms
step:1081/1775 train_time:823906ms step_avg:762.17ms
step:1082/1775 train_time:824712ms step_avg:762.21ms
step:1083/1775 train_time:825506ms step_avg:762.24ms
step:1084/1775 train_time:826308ms step_avg:762.28ms
step:1085/1775 train_time:827106ms step_avg:762.31ms
step:1086/1775 train_time:827912ms step_avg:762.35ms
step:1087/1775 train_time:828704ms step_avg:762.38ms
step:1088/1775 train_time:829509ms step_avg:762.42ms
step:1089/1775 train_time:830304ms step_avg:762.45ms
step:1090/1775 train_time:831108ms step_avg:762.48ms
step:1091/1775 train_time:831905ms step_avg:762.52ms
step:1092/1775 train_time:832708ms step_avg:762.55ms
step:1093/1775 train_time:833506ms step_avg:762.59ms
step:1094/1775 train_time:834315ms step_avg:762.63ms
step:1095/1775 train_time:835109ms step_avg:762.66ms
step:1096/1775 train_time:835911ms step_avg:762.69ms
step:1097/1775 train_time:836705ms step_avg:762.72ms
step:1098/1775 train_time:837506ms step_avg:762.76ms
step:1099/1775 train_time:838303ms step_avg:762.79ms
step:1100/1775 train_time:839111ms step_avg:762.83ms
step:1101/1775 train_time:839905ms step_avg:762.86ms
step:1102/1775 train_time:840710ms step_avg:762.90ms
step:1103/1775 train_time:841507ms step_avg:762.93ms
step:1104/1775 train_time:842309ms step_avg:762.96ms
step:1105/1775 train_time:843104ms step_avg:762.99ms
step:1106/1775 train_time:843907ms step_avg:763.03ms
step:1107/1775 train_time:844709ms step_avg:763.06ms
step:1108/1775 train_time:845514ms step_avg:763.10ms
step:1109/1775 train_time:846319ms step_avg:763.14ms
step:1110/1775 train_time:847120ms step_avg:763.17ms
step:1111/1775 train_time:847910ms step_avg:763.20ms
step:1112/1775 train_time:848708ms step_avg:763.23ms
step:1113/1775 train_time:849506ms step_avg:763.26ms
step:1114/1775 train_time:850308ms step_avg:763.29ms
step:1115/1775 train_time:851106ms step_avg:763.32ms
step:1116/1775 train_time:851914ms step_avg:763.36ms
step:1117/1775 train_time:852700ms step_avg:763.38ms
step:1118/1775 train_time:853505ms step_avg:763.42ms
step:1119/1775 train_time:854302ms step_avg:763.45ms
step:1120/1775 train_time:855108ms step_avg:763.49ms
step:1121/1775 train_time:855906ms step_avg:763.52ms
step:1122/1775 train_time:856709ms step_avg:763.56ms
step:1123/1775 train_time:857503ms step_avg:763.58ms
step:1124/1775 train_time:858308ms step_avg:763.62ms
step:1125/1775 train_time:859106ms step_avg:763.65ms
step:1126/1775 train_time:859907ms step_avg:763.68ms
step:1127/1775 train_time:860704ms step_avg:763.71ms
step:1128/1775 train_time:861509ms step_avg:763.75ms
step:1129/1775 train_time:862301ms step_avg:763.77ms
step:1130/1775 train_time:863107ms step_avg:763.81ms
step:1131/1775 train_time:863902ms step_avg:763.84ms
step:1132/1775 train_time:864711ms step_avg:763.88ms
step:1133/1775 train_time:865507ms step_avg:763.91ms
step:1134/1775 train_time:866309ms step_avg:763.94ms
step:1135/1775 train_time:867105ms step_avg:763.97ms
step:1136/1775 train_time:867911ms step_avg:764.01ms
step:1137/1775 train_time:868706ms step_avg:764.03ms
step:1138/1775 train_time:869510ms step_avg:764.07ms
step:1139/1775 train_time:870299ms step_avg:764.09ms
step:1140/1775 train_time:871103ms step_avg:764.13ms
step:1141/1775 train_time:871904ms step_avg:764.16ms
step:1142/1775 train_time:872707ms step_avg:764.19ms
step:1143/1775 train_time:873501ms step_avg:764.22ms
step:1144/1775 train_time:874312ms step_avg:764.26ms
step:1145/1775 train_time:875115ms step_avg:764.29ms
step:1146/1775 train_time:875915ms step_avg:764.32ms
step:1147/1775 train_time:876708ms step_avg:764.35ms
step:1148/1775 train_time:877512ms step_avg:764.38ms
step:1149/1775 train_time:878305ms step_avg:764.41ms
step:1150/1775 train_time:879107ms step_avg:764.44ms
step:1151/1775 train_time:879913ms step_avg:764.48ms
step:1152/1775 train_time:880718ms step_avg:764.51ms
step:1153/1775 train_time:881509ms step_avg:764.53ms
step:1154/1775 train_time:882309ms step_avg:764.57ms
step:1155/1775 train_time:883103ms step_avg:764.59ms
step:1156/1775 train_time:883905ms step_avg:764.62ms
step:1157/1775 train_time:884708ms step_avg:764.66ms
